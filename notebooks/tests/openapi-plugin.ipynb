{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d826eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "CUR_DIR = Path.cwd()\n",
    "ROOT_DIR = CUR_DIR.parent.parent\n",
    "SRC_DIR = ROOT_DIR / 'src'\n",
    "\n",
    "# Load python modules from the src directory\n",
    "sys.path.append(str(SRC_DIR))\n",
    "print(f\"Added {SRC_DIR} to sys.path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294342bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv(SRC_DIR / '.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3815dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from config import setup_logging\n",
    "\n",
    "setup_logging(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8da2025",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app import create_app_context\n",
    "\n",
    "app_ctx = create_app_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b7fdab",
   "metadata": {},
   "source": [
    "Start a chat to turn on light \"Lamp\". When finished, you should see the following message in the output.\n",
    "\n",
    "```\n",
    "Assistant > The lamp is now turned on. If you need it set to a specific brightness or color, please let me know!\n",
    "```\n",
    "\n",
    "- https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/?pivots=programming-language-python\n",
    "- https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/adding-openapi-plugins?pivots=programming-language-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b815387a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.openapi_plugin import OpenAPIFunctionExecutionParameters\n",
    "from semantic_kernel.functions import kernel_function\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, AzureChatPromptExecutionSettings\n",
    "from semantic_kernel.connectors.ai import FunctionChoiceBehavior\n",
    "from semantic_kernel.contents import ChatHistory, ChatMessageContent, AuthorRole\n",
    "from semantic_kernel.functions import KernelArguments\n",
    "\n",
    "kernel = Kernel()\n",
    "\n",
    " # Add Azure OpenAI chat completion\n",
    "chat_completion = AzureChatCompletion(\n",
    "    deployment_name=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\n",
    "    api_version=\"2024-10-21\",\n",
    "    ad_token_provider=app_ctx.cognitive_services_token_provider\n",
    ")\n",
    "kernel.add_service(chat_completion)\n",
    "\n",
    "kernel.add_plugin_from_openapi(\n",
    "    plugin_name=\"lights\",\n",
    "    openapi_document_path=\"http://localhost:3978/v1/swagger.json\",\n",
    "    execution_settings=OpenAPIFunctionExecutionParameters(\n",
    "        # Inject headers include authorization and chat IDs\n",
    "        # Check web server output to verify headers are sent correctly\n",
    "        auth_callback=lambda: {'Authorization': \"Bearer frank_token\",\n",
    "                               'Teams-Chat-Id': \"19:example_chat_id@\",\n",
    "                               'Agent-Chat-id': \"agent-asdfj-32456\"},\n",
    "        \n",
    "        server_url_override=\"http://localhost:3978\",\n",
    "\n",
    "        # Determines whether payload parameter names are augmented with namespaces.\n",
    "        # Namespaces prevent naming conflicts by adding the parent parameter name\n",
    "        # as a prefix, separated by dots\n",
    "        enable_payload_namespacing=True,\n",
    "   ),\n",
    ")\n",
    "\n",
    "# Enable planning\n",
    "execution_settings = AzureChatPromptExecutionSettings()\n",
    "execution_settings.function_choice_behavior = FunctionChoiceBehavior.Auto()\n",
    "\n",
    "# Create a history of the conversation\n",
    "history = ChatHistory()\n",
    "history.add_message(message=ChatMessageContent(role=AuthorRole.USER, content=\"Please turn on the lamp\"))\n",
    "\n",
    "# Get the response from the AI\n",
    "result = await chat_completion.get_chat_message_content(\n",
    "    chat_history=history,\n",
    "    settings=execution_settings,\n",
    "    kernel=kernel,\n",
    ")\n",
    "\n",
    "# Print the results\n",
    "print(\"Assistant > \" + str(result))\n",
    "\n",
    "# Add the message from the agent to the chat history\n",
    "history.add_message(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

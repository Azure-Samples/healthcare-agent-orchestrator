{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run End-to-end Group Chat\n",
    "\n",
    "This Jupyter Notebook demonstrates the workflow for creating and managing a group chat using Semantic Kernel and custom modules. The notebook integrates various Azure components, such as Key Vault, Blob Storage, and OpenAI services, to facilitate secure and efficient communication. Key functionalities include:\n",
    "\n",
    "- Setting up environment variables and configurations for Azure services.\n",
    "- Initializing and managing chat contexts and data access layers.\n",
    "- Creating a group chat using custom modules and Azure credentials.\n",
    "- Processing chat messages asynchronously and invoking responses.\n",
    "- Exploring chat history and analyzing message content.\n",
    "\n",
    "This notebook serves as a comprehensive guide for implementing a scalable and secure group chat solution leveraging Azure's cloud capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added /mnt/c/biomed-agent/healthcare-agent-orchestrator/src to sys.path\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "CUR_DIR = os.path.abspath(\"\")\n",
    "ROOT_DIR = os.path.dirname(CUR_DIR)\n",
    "SRC_DIR = os.path.join(ROOT_DIR, 'src')\n",
    "\n",
    "# Load python modules from the src directory\n",
    "sys.path.append(SRC_DIR)\n",
    "print(f\"Added {SRC_DIR} to sys.path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv(os.path.join(SRC_DIR, '.env'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from config import setup_logging\n",
    "\n",
    "setup_logging(log_level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-08 13:24:21,998 - IPKernelApp - DEBUG - {'header': {'msg_id': '571bc763-22923a1b7e800ab4f182ecfe_58456_51', 'msg_type': 'execute_reply', 'username': 'mablonde', 'session': '571bc763-22923a1b7e800ab4f182ecfe', 'date': datetime.datetime(2025, 8, 8, 20, 24, 21, 998076, tzinfo=datetime.timezone.utc), 'version': '5.3'}, 'msg_id': '571bc763-22923a1b7e800ab4f182ecfe_58456_51', 'msg_type': 'execute_reply', 'parent_header': {'date': datetime.datetime(2025, 8, 8, 20, 24, 18, 277000, tzinfo=tzutc()), 'msg_id': '505d2ac0-a221-4992-9067-32488ac561ca', 'msg_type': 'execute_request', 'session': '00adb0ca-9d5f-4df4-b793-380b7a539da0', 'username': '8dc24feb-2c65-412a-9798-1ee6e8d34202', 'version': '5.2'}, 'content': {'status': 'ok', 'execution_count': 4, 'user_expressions': {}, 'payload': []}, 'metadata': {'started': datetime.datetime(2025, 8, 8, 20, 24, 18, 279262, tzinfo=datetime.timezone.utc), 'dependencies_met': True, 'engine': '23c0ebcd-44f5-40bd-b21c-85c722302ce7', 'status': 'ok'}, 'tracker': <zmq.sugar.tracker.MessageTracker object at 0x7a2a28801d30>}\n",
      "2025-08-08 13:24:21,998 - IPKernelApp - DEBUG - {'header': {'msg_id': '571bc763-22923a1b7e800ab4f182ecfe_58456_51', 'msg_type': 'execute_reply', 'username': 'mablonde', 'session': '571bc763-22923a1b7e800ab4f182ecfe', 'date': datetime.datetime(2025, 8, 8, 20, 24, 21, 998076, tzinfo=datetime.timezone.utc), 'version': '5.3'}, 'msg_id': '571bc763-22923a1b7e800ab4f182ecfe_58456_51', 'msg_type': 'execute_reply', 'parent_header': {'date': datetime.datetime(2025, 8, 8, 20, 24, 18, 277000, tzinfo=tzutc()), 'msg_id': '505d2ac0-a221-4992-9067-32488ac561ca', 'msg_type': 'execute_request', 'session': '00adb0ca-9d5f-4df4-b793-380b7a539da0', 'username': '8dc24feb-2c65-412a-9798-1ee6e8d34202', 'version': '5.2'}, 'content': {'status': 'ok', 'execution_count': 4, 'user_expressions': {}, 'payload': []}, 'metadata': {'started': datetime.datetime(2025, 8, 8, 20, 24, 18, 279262, tzinfo=datetime.timezone.utc), 'dependencies_met': True, 'engine': '23c0ebcd-44f5-40bd-b21c-85c722302ce7', 'status': 'ok'}, 'tracker': <zmq.sugar.tracker.MessageTracker object at 0x7a2a28801d30>}\n"
     ]
    }
   ],
   "source": [
    "from app import create_app_context\n",
    "from data_models.chat_context import ChatContext\n",
    "\n",
    "\n",
    "app_ctx = create_app_context()\n",
    "chat_ctx = ChatContext(\"notebook-chat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-08 13:24:22,005 - IPKernelApp - DEBUG - \n",
      "*** MESSAGE TYPE:execute_request***\n",
      "2025-08-08 13:24:22,005 - IPKernelApp - DEBUG - \n",
      "*** MESSAGE TYPE:execute_request***\n",
      "2025-08-08 13:24:22,007 - IPKernelApp - DEBUG -    Content: {'silent': False, 'store_history': True, 'user_expressions': {}, 'allow_stdin': True, 'stop_on_error': False, 'code': 'import group_chat\\n\\n\\nchat, context = group_chat.create_group_chat(app_ctx, chat_ctx)'}\n",
      "   --->\n",
      "   \n",
      "2025-08-08 13:24:22,007 - IPKernelApp - DEBUG -    Content: {'silent': False, 'store_history': True, 'user_expressions': {}, 'allow_stdin': True, 'stop_on_error': False, 'code': 'import group_chat\\n\\n\\nchat, context = group_chat.create_group_chat(app_ctx, chat_ctx)'}\n",
      "   --->\n",
      "   \n",
      "2025-08-08 13:24:22,007 - IPKernelApp - DEBUG - execute_request: {'header': {'date': datetime.datetime(2025, 8, 8, 20, 24, 22, 4000, tzinfo=tzutc()), 'msg_id': '72675cb4-15cb-4959-96fa-387190e3f388', 'msg_type': 'execute_request', 'session': '00adb0ca-9d5f-4df4-b793-380b7a539da0', 'username': '8dc24feb-2c65-412a-9798-1ee6e8d34202', 'version': '5.2'}, 'msg_id': '72675cb4-15cb-4959-96fa-387190e3f388', 'msg_type': 'execute_request', 'parent_header': {}, 'metadata': {'cellId': 'vscode-notebook-cell://wsl%2Bubuntu/mnt/c/biomed-agent/healthcare-agent-orchestrator/notebooks/end_to_end_run.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D'}, 'content': {'silent': False, 'store_history': True, 'user_expressions': {}, 'allow_stdin': True, 'stop_on_error': False, 'code': 'import group_chat\\n\\n\\nchat, context = group_chat.create_group_chat(app_ctx, chat_ctx)'}, 'buffers': []}\n",
      "2025-08-08 13:24:22,007 - IPKernelApp - DEBUG - execute_request: {'header': {'date': datetime.datetime(2025, 8, 8, 20, 24, 22, 4000, tzinfo=tzutc()), 'msg_id': '72675cb4-15cb-4959-96fa-387190e3f388', 'msg_type': 'execute_request', 'session': '00adb0ca-9d5f-4df4-b793-380b7a539da0', 'username': '8dc24feb-2c65-412a-9798-1ee6e8d34202', 'version': '5.2'}, 'msg_id': '72675cb4-15cb-4959-96fa-387190e3f388', 'msg_type': 'execute_request', 'parent_header': {}, 'metadata': {'cellId': 'vscode-notebook-cell://wsl%2Bubuntu/mnt/c/biomed-agent/healthcare-agent-orchestrator/notebooks/end_to_end_run.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D'}, 'content': {'silent': False, 'store_history': True, 'user_expressions': {}, 'allow_stdin': True, 'stop_on_error': False, 'code': 'import group_chat\\n\\n\\nchat, context = group_chat.create_group_chat(app_ctx, chat_ctx)'}, 'buffers': []}\n",
      "2025-08-08 13:24:22,125 - group_chat - INFO - Creating group chat with participants: ['Orchestrator', 'PatientHistory', 'Radiology', 'PatientStatus', 'ClinicalGuidelines', 'ReportCreation', 'ClinicalTrials', 'MedicalResearch', 'magentic']\n",
      "2025-08-08 13:24:22,125 - group_chat - INFO - Creating group chat with participants: ['Orchestrator', 'PatientHistory', 'Radiology', 'PatientStatus', 'ClinicalGuidelines', 'ReportCreation', 'ClinicalTrials', 'MedicalResearch', 'magentic']\n",
      "2025-08-08 13:24:23,004 - azure.identity._credentials.environment - INFO - Incomplete environment configuration for EnvironmentCredential. These variables are set: AZURE_TENANT_ID\n",
      "2025-08-08 13:24:23,004 - azure.identity._credentials.environment - INFO - Incomplete environment configuration for EnvironmentCredential. These variables are set: AZURE_TENANT_ID\n",
      "2025-08-08 13:24:23,008 - azure.identity._credentials.managed_identity - INFO - ManagedIdentityCredential will use IMDS\n",
      "2025-08-08 13:24:23,008 - azure.identity._credentials.managed_identity - INFO - ManagedIdentityCredential will use IMDS\n",
      "2025-08-08 13:24:23,011 - azure.core.pipeline.policies.http_logging_policy - INFO - Request URL: 'http://169.254.169.254/metadata/identity/oauth2/token?api-version=REDACTED&resource=REDACTED'\n",
      "Request method: 'GET'\n",
      "Request headers:\n",
      "    'User-Agent': 'azsdk-python-identity/1.19.0 Python/3.12.0 (Linux-6.6.87.2-microsoft-standard-WSL2-x86_64-with-glibc2.35)'\n",
      "No body was attached to the request\n",
      "2025-08-08 13:24:23,011 - azure.core.pipeline.policies.http_logging_policy - INFO - Request URL: 'http://169.254.169.254/metadata/identity/oauth2/token?api-version=REDACTED&resource=REDACTED'\n",
      "Request method: 'GET'\n",
      "Request headers:\n",
      "    'User-Agent': 'azsdk-python-identity/1.19.0 Python/3.12.0 (Linux-6.6.87.2-microsoft-standard-WSL2-x86_64-with-glibc2.35)'\n",
      "No body was attached to the request\n",
      "2025-08-08 13:24:24,629 - azure.identity._credentials.chained - INFO - DefaultAzureCredential acquired a token from AzureCliCredential\n",
      "2025-08-08 13:24:24,629 - azure.identity._credentials.chained - INFO - DefaultAzureCredential acquired a token from AzureCliCredential\n",
      "2025-08-08 13:24:24,724 - IPKernelApp - DEBUG - {'header': {'msg_id': '571bc763-22923a1b7e800ab4f182ecfe_58456_73', 'msg_type': 'execute_reply', 'username': 'mablonde', 'session': '571bc763-22923a1b7e800ab4f182ecfe', 'date': datetime.datetime(2025, 8, 8, 20, 24, 24, 724408, tzinfo=datetime.timezone.utc), 'version': '5.3'}, 'msg_id': '571bc763-22923a1b7e800ab4f182ecfe_58456_73', 'msg_type': 'execute_reply', 'parent_header': {'date': datetime.datetime(2025, 8, 8, 20, 24, 22, 4000, tzinfo=tzutc()), 'msg_id': '72675cb4-15cb-4959-96fa-387190e3f388', 'msg_type': 'execute_request', 'session': '00adb0ca-9d5f-4df4-b793-380b7a539da0', 'username': '8dc24feb-2c65-412a-9798-1ee6e8d34202', 'version': '5.2'}, 'content': {'status': 'ok', 'execution_count': 5, 'user_expressions': {}, 'payload': []}, 'metadata': {'started': datetime.datetime(2025, 8, 8, 20, 24, 22, 8816, tzinfo=datetime.timezone.utc), 'dependencies_met': True, 'engine': '23c0ebcd-44f5-40bd-b21c-85c722302ce7', 'status': 'ok'}, 'tracker': <zmq.sugar.tracker.MessageTracker object at 0x7a2a28801d30>}\n",
      "2025-08-08 13:24:24,724 - IPKernelApp - DEBUG - {'header': {'msg_id': '571bc763-22923a1b7e800ab4f182ecfe_58456_73', 'msg_type': 'execute_reply', 'username': 'mablonde', 'session': '571bc763-22923a1b7e800ab4f182ecfe', 'date': datetime.datetime(2025, 8, 8, 20, 24, 24, 724408, tzinfo=datetime.timezone.utc), 'version': '5.3'}, 'msg_id': '571bc763-22923a1b7e800ab4f182ecfe_58456_73', 'msg_type': 'execute_reply', 'parent_header': {'date': datetime.datetime(2025, 8, 8, 20, 24, 22, 4000, tzinfo=tzutc()), 'msg_id': '72675cb4-15cb-4959-96fa-387190e3f388', 'msg_type': 'execute_request', 'session': '00adb0ca-9d5f-4df4-b793-380b7a539da0', 'username': '8dc24feb-2c65-412a-9798-1ee6e8d34202', 'version': '5.2'}, 'content': {'status': 'ok', 'execution_count': 5, 'user_expressions': {}, 'payload': []}, 'metadata': {'started': datetime.datetime(2025, 8, 8, 20, 24, 22, 8816, tzinfo=datetime.timezone.utc), 'dependencies_met': True, 'engine': '23c0ebcd-44f5-40bd-b21c-85c722302ce7', 'status': 'ok'}, 'tracker': <zmq.sugar.tracker.MessageTracker object at 0x7a2a28801d30>}\n"
     ]
    }
   ],
   "source": [
    "import group_chat\n",
    "\n",
    "\n",
    "chat, context = group_chat.create_group_chat(app_ctx, chat_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-08 13:24:24,732 - IPKernelApp - DEBUG - \n",
      "*** MESSAGE TYPE:execute_request***\n",
      "2025-08-08 13:24:24,732 - IPKernelApp - DEBUG - \n",
      "*** MESSAGE TYPE:execute_request***\n",
      "2025-08-08 13:24:24,734 - IPKernelApp - DEBUG -    Content: {'silent': False, 'store_history': True, 'user_expressions': {}, 'allow_stdin': True, 'stop_on_error': False, 'code': 'from semantic_kernel.agents import AgentGroupChat\\nfrom semantic_kernel.contents.chat_message_content import ChatMessageContent\\nfrom semantic_kernel.contents.utils.author_role import AuthorRole\\n\\n\\nasync def process_chat(chat: AgentGroupChat, user_message: str) -> None:\\n    \"\"\"Process group chat with the given user message.\"\"\"\\n    await chat.add_chat_message(ChatMessageContent(role=AuthorRole.USER, content=user_message))\\n    chat.is_complete = False\\n\\n    async for response in chat.invoke():\\n        print(f\"# {response.role} - {response.name or \\'*\\'}: \\'{response.content}\\'\")\\n        if chat.is_complete:\\n            break\\n\\n\\ndef print_chat_history(chat: AgentGroupChat) -> None:\\n    \"\"\"Print the chat history.\"\"\"\\n    for message in chat.history:\\n        print(f\"{message.name}: {message.content}\")'}\n",
      "   --->\n",
      "   \n",
      "2025-08-08 13:24:24,734 - IPKernelApp - DEBUG -    Content: {'silent': False, 'store_history': True, 'user_expressions': {}, 'allow_stdin': True, 'stop_on_error': False, 'code': 'from semantic_kernel.agents import AgentGroupChat\\nfrom semantic_kernel.contents.chat_message_content import ChatMessageContent\\nfrom semantic_kernel.contents.utils.author_role import AuthorRole\\n\\n\\nasync def process_chat(chat: AgentGroupChat, user_message: str) -> None:\\n    \"\"\"Process group chat with the given user message.\"\"\"\\n    await chat.add_chat_message(ChatMessageContent(role=AuthorRole.USER, content=user_message))\\n    chat.is_complete = False\\n\\n    async for response in chat.invoke():\\n        print(f\"# {response.role} - {response.name or \\'*\\'}: \\'{response.content}\\'\")\\n        if chat.is_complete:\\n            break\\n\\n\\ndef print_chat_history(chat: AgentGroupChat) -> None:\\n    \"\"\"Print the chat history.\"\"\"\\n    for message in chat.history:\\n        print(f\"{message.name}: {message.content}\")'}\n",
      "   --->\n",
      "   \n",
      "2025-08-08 13:24:24,735 - IPKernelApp - DEBUG - execute_request: {'header': {'date': datetime.datetime(2025, 8, 8, 20, 24, 24, 730000, tzinfo=tzutc()), 'msg_id': '08240fa1-f46a-47fd-a2c2-80545ed4ee13', 'msg_type': 'execute_request', 'session': '00adb0ca-9d5f-4df4-b793-380b7a539da0', 'username': '8dc24feb-2c65-412a-9798-1ee6e8d34202', 'version': '5.2'}, 'msg_id': '08240fa1-f46a-47fd-a2c2-80545ed4ee13', 'msg_type': 'execute_request', 'parent_header': {}, 'metadata': {'cellId': 'vscode-notebook-cell://wsl%2Bubuntu/mnt/c/biomed-agent/healthcare-agent-orchestrator/notebooks/end_to_end_run.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D'}, 'content': {'silent': False, 'store_history': True, 'user_expressions': {}, 'allow_stdin': True, 'stop_on_error': False, 'code': 'from semantic_kernel.agents import AgentGroupChat\\nfrom semantic_kernel.contents.chat_message_content import ChatMessageContent\\nfrom semantic_kernel.contents.utils.author_role import AuthorRole\\n\\n\\nasync def process_chat(chat: AgentGroupChat, user_message: str) -> None:\\n    \"\"\"Process group chat with the given user message.\"\"\"\\n    await chat.add_chat_message(ChatMessageContent(role=AuthorRole.USER, content=user_message))\\n    chat.is_complete = False\\n\\n    async for response in chat.invoke():\\n        print(f\"# {response.role} - {response.name or \\'*\\'}: \\'{response.content}\\'\")\\n        if chat.is_complete:\\n            break\\n\\n\\ndef print_chat_history(chat: AgentGroupChat) -> None:\\n    \"\"\"Print the chat history.\"\"\"\\n    for message in chat.history:\\n        print(f\"{message.name}: {message.content}\")'}, 'buffers': []}\n",
      "2025-08-08 13:24:24,735 - IPKernelApp - DEBUG - execute_request: {'header': {'date': datetime.datetime(2025, 8, 8, 20, 24, 24, 730000, tzinfo=tzutc()), 'msg_id': '08240fa1-f46a-47fd-a2c2-80545ed4ee13', 'msg_type': 'execute_request', 'session': '00adb0ca-9d5f-4df4-b793-380b7a539da0', 'username': '8dc24feb-2c65-412a-9798-1ee6e8d34202', 'version': '5.2'}, 'msg_id': '08240fa1-f46a-47fd-a2c2-80545ed4ee13', 'msg_type': 'execute_request', 'parent_header': {}, 'metadata': {'cellId': 'vscode-notebook-cell://wsl%2Bubuntu/mnt/c/biomed-agent/healthcare-agent-orchestrator/notebooks/end_to_end_run.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D'}, 'content': {'silent': False, 'store_history': True, 'user_expressions': {}, 'allow_stdin': True, 'stop_on_error': False, 'code': 'from semantic_kernel.agents import AgentGroupChat\\nfrom semantic_kernel.contents.chat_message_content import ChatMessageContent\\nfrom semantic_kernel.contents.utils.author_role import AuthorRole\\n\\n\\nasync def process_chat(chat: AgentGroupChat, user_message: str) -> None:\\n    \"\"\"Process group chat with the given user message.\"\"\"\\n    await chat.add_chat_message(ChatMessageContent(role=AuthorRole.USER, content=user_message))\\n    chat.is_complete = False\\n\\n    async for response in chat.invoke():\\n        print(f\"# {response.role} - {response.name or \\'*\\'}: \\'{response.content}\\'\")\\n        if chat.is_complete:\\n            break\\n\\n\\ndef print_chat_history(chat: AgentGroupChat) -> None:\\n    \"\"\"Print the chat history.\"\"\"\\n    for message in chat.history:\\n        print(f\"{message.name}: {message.content}\")'}, 'buffers': []}\n",
      "2025-08-08 13:24:24,894 - IPKernelApp - DEBUG - {'header': {'msg_id': '571bc763-22923a1b7e800ab4f182ecfe_58456_85', 'msg_type': 'execute_reply', 'username': 'mablonde', 'session': '571bc763-22923a1b7e800ab4f182ecfe', 'date': datetime.datetime(2025, 8, 8, 20, 24, 24, 893928, tzinfo=datetime.timezone.utc), 'version': '5.3'}, 'msg_id': '571bc763-22923a1b7e800ab4f182ecfe_58456_85', 'msg_type': 'execute_reply', 'parent_header': {'date': datetime.datetime(2025, 8, 8, 20, 24, 24, 730000, tzinfo=tzutc()), 'msg_id': '08240fa1-f46a-47fd-a2c2-80545ed4ee13', 'msg_type': 'execute_request', 'session': '00adb0ca-9d5f-4df4-b793-380b7a539da0', 'username': '8dc24feb-2c65-412a-9798-1ee6e8d34202', 'version': '5.2'}, 'content': {'status': 'ok', 'execution_count': 6, 'user_expressions': {}, 'payload': []}, 'metadata': {'started': datetime.datetime(2025, 8, 8, 20, 24, 24, 736949, tzinfo=datetime.timezone.utc), 'dependencies_met': True, 'engine': '23c0ebcd-44f5-40bd-b21c-85c722302ce7', 'status': 'ok'}, 'tracker': <zmq.sugar.tracker.MessageTracker object at 0x7a2a28801d30>}\n",
      "2025-08-08 13:24:24,894 - IPKernelApp - DEBUG - {'header': {'msg_id': '571bc763-22923a1b7e800ab4f182ecfe_58456_85', 'msg_type': 'execute_reply', 'username': 'mablonde', 'session': '571bc763-22923a1b7e800ab4f182ecfe', 'date': datetime.datetime(2025, 8, 8, 20, 24, 24, 893928, tzinfo=datetime.timezone.utc), 'version': '5.3'}, 'msg_id': '571bc763-22923a1b7e800ab4f182ecfe_58456_85', 'msg_type': 'execute_reply', 'parent_header': {'date': datetime.datetime(2025, 8, 8, 20, 24, 24, 730000, tzinfo=tzutc()), 'msg_id': '08240fa1-f46a-47fd-a2c2-80545ed4ee13', 'msg_type': 'execute_request', 'session': '00adb0ca-9d5f-4df4-b793-380b7a539da0', 'username': '8dc24feb-2c65-412a-9798-1ee6e8d34202', 'version': '5.2'}, 'content': {'status': 'ok', 'execution_count': 6, 'user_expressions': {}, 'payload': []}, 'metadata': {'started': datetime.datetime(2025, 8, 8, 20, 24, 24, 736949, tzinfo=datetime.timezone.utc), 'dependencies_met': True, 'engine': '23c0ebcd-44f5-40bd-b21c-85c722302ce7', 'status': 'ok'}, 'tracker': <zmq.sugar.tracker.MessageTracker object at 0x7a2a28801d30>}\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.agents import AgentGroupChat\n",
    "from semantic_kernel.contents.chat_message_content import ChatMessageContent\n",
    "from semantic_kernel.contents.utils.author_role import AuthorRole\n",
    "\n",
    "\n",
    "async def process_chat(chat: AgentGroupChat, user_message: str) -> None:\n",
    "    \"\"\"Process group chat with the given user message.\"\"\"\n",
    "    await chat.add_chat_message(ChatMessageContent(role=AuthorRole.USER, content=user_message))\n",
    "    chat.is_complete = False\n",
    "\n",
    "    async for response in chat.invoke():\n",
    "        print(f\"# {response.role} - {response.name or '*'}: '{response.content}'\")\n",
    "        if chat.is_complete:\n",
    "            break\n",
    "\n",
    "\n",
    "def print_chat_history(chat: AgentGroupChat) -> None:\n",
    "    \"\"\"Print the chat history.\"\"\"\n",
    "    for message in chat.history:\n",
    "        print(f\"{message.name}: {message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-08 13:24:24,901 - IPKernelApp - DEBUG - \n",
      "*** MESSAGE TYPE:execute_request***\n",
      "2025-08-08 13:24:24,901 - IPKernelApp - DEBUG - \n",
      "*** MESSAGE TYPE:execute_request***\n",
      "2025-08-08 13:24:24,903 - IPKernelApp - DEBUG -    Content: {'silent': False, 'store_history': True, 'user_expressions': {}, 'allow_stdin': True, 'stop_on_error': False, 'code': 'await process_chat(chat, \"Orchestrator: Prepare tumor board for Patient ID: patient_4\")'}\n",
      "   --->\n",
      "   \n",
      "2025-08-08 13:24:24,903 - IPKernelApp - DEBUG -    Content: {'silent': False, 'store_history': True, 'user_expressions': {}, 'allow_stdin': True, 'stop_on_error': False, 'code': 'await process_chat(chat, \"Orchestrator: Prepare tumor board for Patient ID: patient_4\")'}\n",
      "   --->\n",
      "   \n",
      "2025-08-08 13:24:24,904 - IPKernelApp - DEBUG - execute_request: {'header': {'date': datetime.datetime(2025, 8, 8, 20, 24, 24, 899000, tzinfo=tzutc()), 'msg_id': '8bff73fc-2beb-4dfb-92c7-172c72498c0b', 'msg_type': 'execute_request', 'session': '00adb0ca-9d5f-4df4-b793-380b7a539da0', 'username': '8dc24feb-2c65-412a-9798-1ee6e8d34202', 'version': '5.2'}, 'msg_id': '8bff73fc-2beb-4dfb-92c7-172c72498c0b', 'msg_type': 'execute_request', 'parent_header': {}, 'metadata': {'cellId': 'vscode-notebook-cell://wsl%2Bubuntu/mnt/c/biomed-agent/healthcare-agent-orchestrator/notebooks/end_to_end_run.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D'}, 'content': {'silent': False, 'store_history': True, 'user_expressions': {}, 'allow_stdin': True, 'stop_on_error': False, 'code': 'await process_chat(chat, \"Orchestrator: Prepare tumor board for Patient ID: patient_4\")'}, 'buffers': []}\n",
      "2025-08-08 13:24:24,904 - IPKernelApp - DEBUG - execute_request: {'header': {'date': datetime.datetime(2025, 8, 8, 20, 24, 24, 899000, tzinfo=tzutc()), 'msg_id': '8bff73fc-2beb-4dfb-92c7-172c72498c0b', 'msg_type': 'execute_request', 'session': '00adb0ca-9d5f-4df4-b793-380b7a539da0', 'username': '8dc24feb-2c65-412a-9798-1ee6e8d34202', 'version': '5.2'}, 'msg_id': '8bff73fc-2beb-4dfb-92c7-172c72498c0b', 'msg_type': 'execute_request', 'parent_header': {}, 'metadata': {'cellId': 'vscode-notebook-cell://wsl%2Bubuntu/mnt/c/biomed-agent/healthcare-agent-orchestrator/notebooks/end_to_end_run.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D'}, 'content': {'silent': False, 'store_history': True, 'user_expressions': {}, 'allow_stdin': True, 'stop_on_error': False, 'code': 'await process_chat(chat, \"Orchestrator: Prepare tumor board for Patient ID: patient_4\")'}, 'buffers': []}\n",
      "2025-08-08 13:24:25,056 - semantic_kernel.agents.group_chat.agent_chat - INFO - Adding `1` agent chat messages\n",
      "2025-08-08 13:24:25,056 - semantic_kernel.agents.group_chat.agent_chat - INFO - Adding `1` agent chat messages\n",
      "2025-08-08 13:24:25,059 - semantic_kernel.agents.strategies.selection.kernel_function_selection_strategy - INFO - Kernel Function Selection Strategy next method called, invoking function: , selection\n",
      "2025-08-08 13:24:25,059 - semantic_kernel.agents.strategies.selection.kernel_function_selection_strategy - INFO - Kernel Function Selection Strategy next method called, invoking function: , selection\n",
      "2025-08-08 13:24:25,072 - semantic_kernel.functions.kernel_function - INFO - Function selection invoking.\n",
      "2025-08-08 13:24:25,072 - semantic_kernel.functions.kernel_function - INFO - Function selection invoking.\n",
      "2025-08-08 13:24:25,579 - azure.identity._internal.decorators - INFO - AzureCliCredential.get_token_info succeeded\n",
      "2025-08-08 13:24:25,579 - azure.identity._internal.decorators - INFO - AzureCliCredential.get_token_info succeeded\n",
      "2025-08-08 13:24:26,053 - httpx - INFO - HTTP Request: POST https://cog-ma-ba-1-3zo.cognitiveservices.azure.com/openai/deployments/gpt-5-chat/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 400 Bad Request\"\n",
      "2025-08-08 13:24:26,053 - httpx - INFO - HTTP Request: POST https://cog-ma-ba-1-3zo.cognitiveservices.azure.com/openai/deployments/gpt-5-chat/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 400 Bad Request\"\n",
      "2025-08-08 13:24:26,067 - semantic_kernel.functions.kernel_function - ERROR - Function failed. Error: Error occurred while invoking function selection: (\"<class 'semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion.AzureChatCompletion'> service failed to complete the prompt\", BadRequestError('Error code: 400 - {\\'error\\': {\\'message\\': \"Invalid parameter: \\'response_format\\' of type \\'json_schema\\' is not supported with this model. Learn more about supported models at the Structured Outputs guide: https://platform.openai.com/docs/guides/structured-outputs\", \\'type\\': \\'invalid_request_error\\', \\'param\\': None, \\'code\\': None}}'))\n",
      "2025-08-08 13:24:26,067 - semantic_kernel.functions.kernel_function - ERROR - Function failed. Error: Error occurred while invoking function selection: (\"<class 'semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion.AzureChatCompletion'> service failed to complete the prompt\", BadRequestError('Error code: 400 - {\\'error\\': {\\'message\\': \"Invalid parameter: \\'response_format\\' of type \\'json_schema\\' is not supported with this model. Learn more about supported models at the Structured Outputs guide: https://platform.openai.com/docs/guides/structured-outputs\", \\'type\\': \\'invalid_request_error\\', \\'param\\': None, \\'code\\': None}}'))\n",
      "2025-08-08 13:24:26,071 - semantic_kernel.functions.kernel_function - INFO - Function completed. Duration: 0.996852s\n",
      "2025-08-08 13:24:26,071 - semantic_kernel.functions.kernel_function - INFO - Function completed. Duration: 0.996852s\n",
      "2025-08-08 13:24:26,076 - semantic_kernel.agents.strategies.selection.kernel_function_selection_strategy - ERROR - Kernel Function Selection Strategy next method failed\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mablonde/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_handler.py\", line 88, in _send_completion_request\n",
      "    response = await self.client.chat.completions.create(**settings_dict)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mablonde/miniforge3/envs/biomed/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2589, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mablonde/miniforge3/envs/biomed/lib/python3.12/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mablonde/miniforge3/envs/biomed/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_schema' is not supported with this model. Learn more about supported models at the Structured Outputs guide: https://platform.openai.com/docs/guides/structured-outputs\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mablonde/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/functions/kernel_function_from_prompt.py\", line 178, in _invoke_internal\n",
      "    chat_message_contents = await prompt_render_result.ai_service.get_chat_message_contents(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mablonde/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/connectors/ai/chat_completion_client_base.py\", line 139, in get_chat_message_contents\n",
      "    completions = await self._inner_get_chat_message_contents(chat_history, settings)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mablonde/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/utils/telemetry/model_diagnostics/decorators.py\", line 112, in wrapper_decorator\n",
      "    return await completion_func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mablonde/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_chat_completion_base.py\", line 88, in _inner_get_chat_message_contents\n",
      "    response = await self._send_request(settings)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mablonde/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_handler.py\", line 60, in _send_request\n",
      "    return await self._send_completion_request(settings)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mablonde/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_handler.py\", line 100, in _send_completion_request\n",
      "    raise ServiceResponseException(\n",
      "semantic_kernel.exceptions.service_exceptions.ServiceResponseException: (\"<class 'semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion.AzureChatCompletion'> service failed to complete the prompt\", BadRequestError('Error code: 400 - {\\'error\\': {\\'message\\': \"Invalid parameter: \\'response_format\\' of type \\'json_schema\\' is not supported with this model. Learn more about supported models at the Structured Outputs guide: https://platform.openai.com/docs/guides/structured-outputs\", \\'type\\': \\'invalid_request_error\\', \\'param\\': None, \\'code\\': None}}'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mablonde/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/agents/strategies/selection/kernel_function_selection_strategy.py\", line 95, in select_agent\n",
      "    result = await self.function.invoke(kernel=self.kernel, arguments=arguments)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mablonde/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/functions/kernel_function.py\", line 259, in invoke\n",
      "    raise e\n",
      "  File \"/home/mablonde/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/functions/kernel_function.py\", line 251, in invoke\n",
      "    await stack(function_context)\n",
      "  File \"/home/mablonde/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/functions/kernel_function_from_prompt.py\", line 184, in _invoke_internal\n",
      "    raise FunctionExecutionException(f\"Error occurred while invoking function {self.name}: {exc}\") from exc\n",
      "semantic_kernel.exceptions.function_exceptions.FunctionExecutionException: Error occurred while invoking function selection: (\"<class 'semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion.AzureChatCompletion'> service failed to complete the prompt\", BadRequestError('Error code: 400 - {\\'error\\': {\\'message\\': \"Invalid parameter: \\'response_format\\' of type \\'json_schema\\' is not supported with this model. Learn more about supported models at the Structured Outputs guide: https://platform.openai.com/docs/guides/structured-outputs\", \\'type\\': \\'invalid_request_error\\', \\'param\\': None, \\'code\\': None}}'))\n",
      "2025-08-08 13:24:26,076 - semantic_kernel.agents.strategies.selection.kernel_function_selection_strategy - ERROR - Kernel Function Selection Strategy next method failed\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mablonde/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_handler.py\", line 88, in _send_completion_request\n",
      "    response = await self.client.chat.completions.create(**settings_dict)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mablonde/miniforge3/envs/biomed/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2589, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mablonde/miniforge3/envs/biomed/lib/python3.12/site-packages/openai/_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mablonde/miniforge3/envs/biomed/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_schema' is not supported with this model. Learn more about supported models at the Structured Outputs guide: https://platform.openai.com/docs/guides/structured-outputs\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mablonde/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/functions/kernel_function_from_prompt.py\", line 178, in _invoke_internal\n",
      "    chat_message_contents = await prompt_render_result.ai_service.get_chat_message_contents(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mablonde/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/connectors/ai/chat_completion_client_base.py\", line 139, in get_chat_message_contents\n",
      "    completions = await self._inner_get_chat_message_contents(chat_history, settings)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mablonde/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/utils/telemetry/model_diagnostics/decorators.py\", line 112, in wrapper_decorator\n",
      "    return await completion_func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mablonde/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_chat_completion_base.py\", line 88, in _inner_get_chat_message_contents\n",
      "    response = await self._send_request(settings)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mablonde/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_handler.py\", line 60, in _send_request\n",
      "    return await self._send_completion_request(settings)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mablonde/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_handler.py\", line 100, in _send_completion_request\n",
      "    raise ServiceResponseException(\n",
      "semantic_kernel.exceptions.service_exceptions.ServiceResponseException: (\"<class 'semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion.AzureChatCompletion'> service failed to complete the prompt\", BadRequestError('Error code: 400 - {\\'error\\': {\\'message\\': \"Invalid parameter: \\'response_format\\' of type \\'json_schema\\' is not supported with this model. Learn more about supported models at the Structured Outputs guide: https://platform.openai.com/docs/guides/structured-outputs\", \\'type\\': \\'invalid_request_error\\', \\'param\\': None, \\'code\\': None}}'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mablonde/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/agents/strategies/selection/kernel_function_selection_strategy.py\", line 95, in select_agent\n",
      "    result = await self.function.invoke(kernel=self.kernel, arguments=arguments)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mablonde/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/functions/kernel_function.py\", line 259, in invoke\n",
      "    raise e\n",
      "  File \"/home/mablonde/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/functions/kernel_function.py\", line 251, in invoke\n",
      "    await stack(function_context)\n",
      "  File \"/home/mablonde/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/functions/kernel_function_from_prompt.py\", line 184, in _invoke_internal\n",
      "    raise FunctionExecutionException(f\"Error occurred while invoking function {self.name}: {exc}\") from exc\n",
      "semantic_kernel.exceptions.function_exceptions.FunctionExecutionException: Error occurred while invoking function selection: (\"<class 'semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion.AzureChatCompletion'> service failed to complete the prompt\", BadRequestError('Error code: 400 - {\\'error\\': {\\'message\\': \"Invalid parameter: \\'response_format\\' of type \\'json_schema\\' is not supported with this model. Learn more about supported models at the Structured Outputs guide: https://platform.openai.com/docs/guides/structured-outputs\", \\'type\\': \\'invalid_request_error\\', \\'param\\': None, \\'code\\': None}}'))\n",
      "2025-08-08 13:24:26,079 - semantic_kernel.agents.group_chat.agent_group_chat - ERROR - Failed to select agent: Agent Failure - Strategy failed to execute function.\n",
      "2025-08-08 13:24:26,079 - semantic_kernel.agents.group_chat.agent_group_chat - ERROR - Failed to select agent: Agent Failure - Strategy failed to execute function.\n"
     ]
    },
    {
     "ename": "AgentChatException",
     "evalue": "Failed to select agent",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_handler.py:88\u001b[0m, in \u001b[0;36mOpenAIHandler._send_completion_request\u001b[0;34m(self, settings)\u001b[0m\n\u001b[1;32m     87\u001b[0m         settings_dict\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m---> 88\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msettings_dict)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:2589\u001b[0m, in \u001b[0;36mAsyncCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   2588\u001b[0m validate_response_format(response_format)\n\u001b[0;32m-> 2589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[1;32m   2590\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2591\u001b[0m     body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[1;32m   2592\u001b[0m         {\n\u001b[1;32m   2593\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[1;32m   2594\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[1;32m   2595\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m: audio,\n\u001b[1;32m   2596\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[1;32m   2597\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[1;32m   2598\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[1;32m   2599\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[1;32m   2600\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[1;32m   2601\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_completion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_completion_tokens,\n\u001b[1;32m   2602\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[1;32m   2603\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m   2604\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodalities\u001b[39m\u001b[38;5;124m\"\u001b[39m: modalities,\n\u001b[1;32m   2605\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[1;32m   2606\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[1;32m   2607\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m: prediction,\n\u001b[1;32m   2608\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[1;32m   2609\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_cache_key\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt_cache_key,\n\u001b[1;32m   2610\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning_effort\u001b[39m\u001b[38;5;124m\"\u001b[39m: reasoning_effort,\n\u001b[1;32m   2611\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[1;32m   2612\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msafety_identifier\u001b[39m\u001b[38;5;124m\"\u001b[39m: safety_identifier,\n\u001b[1;32m   2613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[1;32m   2614\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[1;32m   2615\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[1;32m   2616\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m: store,\n\u001b[1;32m   2617\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[1;32m   2618\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[1;32m   2619\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[1;32m   2620\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[1;32m   2621\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[1;32m   2622\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[1;32m   2623\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[1;32m   2624\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[1;32m   2625\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbosity\u001b[39m\u001b[38;5;124m\"\u001b[39m: verbosity,\n\u001b[1;32m   2626\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweb_search_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: web_search_options,\n\u001b[1;32m   2627\u001b[0m         },\n\u001b[1;32m   2628\u001b[0m         completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParamsStreaming\n\u001b[1;32m   2629\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[1;32m   2630\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParamsNonStreaming,\n\u001b[1;32m   2631\u001b[0m     ),\n\u001b[1;32m   2632\u001b[0m     options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[1;32m   2633\u001b[0m         extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m   2634\u001b[0m     ),\n\u001b[1;32m   2635\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[1;32m   2636\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   2637\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mAsyncStream[ChatCompletionChunk],\n\u001b[1;32m   2638\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/openai/_base_client.py:1794\u001b[0m, in \u001b[0;36mAsyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1791\u001b[0m opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1792\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1793\u001b[0m )\n\u001b[0;32m-> 1794\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls)\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/openai/_base_client.py:1594\u001b[0m, in \u001b[0;36mAsyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1593\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1594\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1596\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_schema' is not supported with this model. Learn more about supported models at the Structured Outputs guide: https://platform.openai.com/docs/guides/structured-outputs\", 'type': 'invalid_request_error', 'param': None, 'code': None}}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mServiceResponseException\u001b[0m                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/functions/kernel_function_from_prompt.py:178\u001b[0m, in \u001b[0;36mKernelFunctionFromPrompt._invoke_internal\u001b[0;34m(self, context)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m     chat_message_contents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m prompt_render_result\u001b[38;5;241m.\u001b[39mai_service\u001b[38;5;241m.\u001b[39mget_chat_message_contents(\n\u001b[1;32m    179\u001b[0m         chat_history\u001b[38;5;241m=\u001b[39mchat_history,\n\u001b[1;32m    180\u001b[0m         settings\u001b[38;5;241m=\u001b[39mprompt_render_result\u001b[38;5;241m.\u001b[39mexecution_settings,\n\u001b[1;32m    181\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m\"\u001b[39m: context\u001b[38;5;241m.\u001b[39mkernel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marguments\u001b[39m\u001b[38;5;124m\"\u001b[39m: context\u001b[38;5;241m.\u001b[39marguments},\n\u001b[1;32m    182\u001b[0m     )\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/connectors/ai/chat_completion_client_base.py:139\u001b[0m, in \u001b[0;36mChatCompletionClientBase.get_chat_message_contents\u001b[0;34m(self, chat_history, settings, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m request_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(settings\u001b[38;5;241m.\u001b[39mfunction_choice_behavior\u001b[38;5;241m.\u001b[39mmaximum_auto_invoke_attempts):\n\u001b[0;32m--> 139\u001b[0m     completions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_get_chat_message_contents(chat_history, settings)\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# Get the function call contents from the chat message. There is only one chat message,\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# which should be checked in the `_verify_function_choice_settings` method.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/utils/telemetry/model_diagnostics/decorators.py:112\u001b[0m, in \u001b[0;36mtrace_chat_completion.<locals>.inner_trace_chat_completion.<locals>.wrapper_decorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m are_model_diagnostics_enabled():\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;66;03m# If model diagnostics are not enabled, just return the completion\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m completion_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    114\u001b[0m completion_service: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatCompletionClientBase\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_chat_completion_base.py:88\u001b[0m, in \u001b[0;36mOpenAIChatCompletionBase._inner_get_chat_message_contents\u001b[0;34m(self, chat_history, settings)\u001b[0m\n\u001b[1;32m     86\u001b[0m settings\u001b[38;5;241m.\u001b[39mai_model_id \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mai_model_id \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mai_model_id\n\u001b[0;32m---> 88\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_request(settings)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, ChatCompletion)  \u001b[38;5;66;03m# nosec\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_handler.py:60\u001b[0m, in \u001b[0;36mOpenAIHandler._send_request\u001b[0;34m(self, settings)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(settings, OpenAIPromptExecutionSettings)  \u001b[38;5;66;03m# nosec\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_completion_request(settings)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mai_model_type \u001b[38;5;241m==\u001b[39m OpenAIModelTypes\u001b[38;5;241m.\u001b[39mEMBEDDING:\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_handler.py:100\u001b[0m, in \u001b[0;36mOpenAIHandler._send_completion_request\u001b[0;34m(self, settings)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ContentFilterAIException(\n\u001b[1;32m     97\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m service encountered a content error\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     98\u001b[0m             ex,\n\u001b[1;32m     99\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mex\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceResponseException(\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m service failed to complete the prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    102\u001b[0m         ex,\n\u001b[1;32m    103\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mex\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "\u001b[0;31mServiceResponseException\u001b[0m: (\"<class 'semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion.AzureChatCompletion'> service failed to complete the prompt\", BadRequestError('Error code: 400 - {\\'error\\': {\\'message\\': \"Invalid parameter: \\'response_format\\' of type \\'json_schema\\' is not supported with this model. Learn more about supported models at the Structured Outputs guide: https://platform.openai.com/docs/guides/structured-outputs\", \\'type\\': \\'invalid_request_error\\', \\'param\\': None, \\'code\\': None}}'))",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFunctionExecutionException\u001b[0m                Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/agents/strategies/selection/kernel_function_selection_strategy.py:95\u001b[0m, in \u001b[0;36mKernelFunctionSelectionStrategy.select_agent\u001b[0;34m(self, agents, history)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 95\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39minvoke(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel, arguments\u001b[38;5;241m=\u001b[39marguments)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/functions/kernel_function.py:259\u001b[0m, in \u001b[0;36mKernelFunction.invoke\u001b[0;34m(self, kernel, arguments, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_exception(current_span, e, attributes)\n\u001b[0;32m--> 259\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/functions/kernel_function.py:251\u001b[0m, in \u001b[0;36mKernelFunction.invoke\u001b[0;34m(self, kernel, arguments, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    247\u001b[0m stack \u001b[38;5;241m=\u001b[39m kernel\u001b[38;5;241m.\u001b[39mconstruct_call_stack(\n\u001b[1;32m    248\u001b[0m     filter_type\u001b[38;5;241m=\u001b[39mFilterTypes\u001b[38;5;241m.\u001b[39mFUNCTION_INVOCATION,\n\u001b[1;32m    249\u001b[0m     inner_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invoke_internal,\n\u001b[1;32m    250\u001b[0m )\n\u001b[0;32m--> 251\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m stack(function_context)\n\u001b[1;32m    253\u001b[0m KernelFunctionLogMessages\u001b[38;5;241m.\u001b[39mlog_function_invoked_success(logger, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfully_qualified_name)\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/functions/kernel_function_from_prompt.py:184\u001b[0m, in \u001b[0;36mKernelFunctionFromPrompt._invoke_internal\u001b[0;34m(self, context)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m--> 184\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FunctionExecutionException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError occurred while invoking function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chat_message_contents:\n",
      "\u001b[0;31mFunctionExecutionException\u001b[0m: Error occurred while invoking function selection: (\"<class 'semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion.AzureChatCompletion'> service failed to complete the prompt\", BadRequestError('Error code: 400 - {\\'error\\': {\\'message\\': \"Invalid parameter: \\'response_format\\' of type \\'json_schema\\' is not supported with this model. Learn more about supported models at the Structured Outputs guide: https://platform.openai.com/docs/guides/structured-outputs\", \\'type\\': \\'invalid_request_error\\', \\'param\\': None, \\'code\\': None}}'))",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAgentExecutionException\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/agents/group_chat/agent_group_chat.py:151\u001b[0m, in \u001b[0;36mAgentGroupChat.invoke\u001b[0;34m(self, agent, is_joining)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 151\u001b[0m     selected_agent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselection_strategy\u001b[38;5;241m.\u001b[39mnext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magents, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mmessages)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/agents/strategies/selection/selection_strategy.py:43\u001b[0m, in \u001b[0;36mSelectionStrategy.next\u001b[0;34m(self, agents, history)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 43\u001b[0m     agent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselect_agent(agents, history)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_selected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/agents/strategies/selection/kernel_function_selection_strategy.py:98\u001b[0m, in \u001b[0;36mKernelFunctionSelectionStrategy.select_agent\u001b[0;34m(self, agents, history)\u001b[0m\n\u001b[1;32m     97\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKernel Function Selection Strategy next method failed\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39mex)\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m AgentExecutionException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgent Failure - Strategy failed to execute function.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mex\u001b[39;00m\n\u001b[1;32m    100\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKernel Function Selection Strategy next method completed: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39mplugin_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, result: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mresult\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    103\u001b[0m )\n",
      "\u001b[0;31mAgentExecutionException\u001b[0m: Agent Failure - Strategy failed to execute function.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAgentChatException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m process_chat(chat, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOrchestrator: Prepare tumor board for Patient ID: patient_4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m, in \u001b[0;36mprocess_chat\u001b[0;34m(chat, user_message)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m chat\u001b[38;5;241m.\u001b[39madd_chat_message(ChatMessageContent(role\u001b[38;5;241m=\u001b[39mAuthorRole\u001b[38;5;241m.\u001b[39mUSER, content\u001b[38;5;241m=\u001b[39muser_message))\n\u001b[1;32m      9\u001b[0m chat\u001b[38;5;241m.\u001b[39mis_complete \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m chat\u001b[38;5;241m.\u001b[39minvoke():\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mrole\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mname\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chat\u001b[38;5;241m.\u001b[39mis_complete:\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/agents/group_chat/agent_group_chat.py:154\u001b[0m, in \u001b[0;36mAgentGroupChat.invoke\u001b[0;34m(self, agent, is_joining)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m    153\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to select agent: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m AgentChatException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to select agent\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mex\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39minvoke_agent(selected_agent):\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m message\u001b[38;5;241m.\u001b[39mrole \u001b[38;5;241m==\u001b[39m AuthorRole\u001b[38;5;241m.\u001b[39mASSISTANT:\n",
      "\u001b[0;31mAgentChatException\u001b[0m: Failed to select agent"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-08 13:24:27,160 - IPKernelApp - INFO - Exception in execute request:\n",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_handler.py:88\u001b[0m, in \u001b[0;36mOpenAIHandler._send_completion_request\u001b[0;34m(self, settings)\u001b[0m\n",
      "\u001b[1;32m     87\u001b[0m         settings_dict\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;32m---> 88\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msettings_dict)\n",
      "\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:2589\u001b[0m, in \u001b[0;36mAsyncCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n",
      "\u001b[1;32m   2588\u001b[0m validate_response_format(response_format)\n",
      "\u001b[0;32m-> 2589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n",
      "\u001b[1;32m   2590\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[1;32m   2591\u001b[0m     body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n",
      "\u001b[1;32m   2592\u001b[0m         {\n",
      "\u001b[1;32m   2593\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n",
      "\u001b[1;32m   2594\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n",
      "\u001b[1;32m   2595\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m: audio,\n",
      "\u001b[1;32m   2596\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n",
      "\u001b[1;32m   2597\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n",
      "\u001b[1;32m   2598\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n",
      "\u001b[1;32m   2599\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n",
      "\u001b[1;32m   2600\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n",
      "\u001b[1;32m   2601\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_completion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_completion_tokens,\n",
      "\u001b[1;32m   2602\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n",
      "\u001b[1;32m   2603\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n",
      "\u001b[1;32m   2604\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodalities\u001b[39m\u001b[38;5;124m\"\u001b[39m: modalities,\n",
      "\u001b[1;32m   2605\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n",
      "\u001b[1;32m   2606\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n",
      "\u001b[1;32m   2607\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m: prediction,\n",
      "\u001b[1;32m   2608\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n",
      "\u001b[1;32m   2609\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_cache_key\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt_cache_key,\n",
      "\u001b[1;32m   2610\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning_effort\u001b[39m\u001b[38;5;124m\"\u001b[39m: reasoning_effort,\n",
      "\u001b[1;32m   2611\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n",
      "\u001b[1;32m   2612\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msafety_identifier\u001b[39m\u001b[38;5;124m\"\u001b[39m: safety_identifier,\n",
      "\u001b[1;32m   2613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n",
      "\u001b[1;32m   2614\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n",
      "\u001b[1;32m   2615\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n",
      "\u001b[1;32m   2616\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m: store,\n",
      "\u001b[1;32m   2617\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n",
      "\u001b[1;32m   2618\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n",
      "\u001b[1;32m   2619\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n",
      "\u001b[1;32m   2620\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n",
      "\u001b[1;32m   2621\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n",
      "\u001b[1;32m   2622\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n",
      "\u001b[1;32m   2623\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n",
      "\u001b[1;32m   2624\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n",
      "\u001b[1;32m   2625\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbosity\u001b[39m\u001b[38;5;124m\"\u001b[39m: verbosity,\n",
      "\u001b[1;32m   2626\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweb_search_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: web_search_options,\n",
      "\u001b[1;32m   2627\u001b[0m         },\n",
      "\u001b[1;32m   2628\u001b[0m         completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParamsStreaming\n",
      "\u001b[1;32m   2629\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m stream\n",
      "\u001b[1;32m   2630\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParamsNonStreaming,\n",
      "\u001b[1;32m   2631\u001b[0m     ),\n",
      "\u001b[1;32m   2632\u001b[0m     options\u001b[38;5;241m=\u001b[39mmake_request_options(\n",
      "\u001b[1;32m   2633\u001b[0m         extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n",
      "\u001b[1;32m   2634\u001b[0m     ),\n",
      "\u001b[1;32m   2635\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n",
      "\u001b[1;32m   2636\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "\u001b[1;32m   2637\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mAsyncStream[ChatCompletionChunk],\n",
      "\u001b[1;32m   2638\u001b[0m )\n",
      "\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/openai/_base_client.py:1794\u001b[0m, in \u001b[0;36mAsyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[0m\n",
      "\u001b[1;32m   1791\u001b[0m opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n",
      "\u001b[1;32m   1792\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n",
      "\u001b[1;32m   1793\u001b[0m )\n",
      "\u001b[0;32m-> 1794\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls)\n",
      "\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/openai/_base_client.py:1594\u001b[0m, in \u001b[0;36mAsyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n",
      "\u001b[1;32m   1593\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;32m-> 1594\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m   1596\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_schema' is not supported with this model. Learn more about supported models at the Structured Outputs guide: https://platform.openai.com/docs/guides/structured-outputs\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[0;31mServiceResponseException\u001b[0m                  Traceback (most recent call last)\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/functions/kernel_function_from_prompt.py:178\u001b[0m, in \u001b[0;36mKernelFunctionFromPrompt._invoke_internal\u001b[0;34m(self, context)\u001b[0m\n",
      "\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 178\u001b[0m     chat_message_contents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m prompt_render_result\u001b[38;5;241m.\u001b[39mai_service\u001b[38;5;241m.\u001b[39mget_chat_message_contents(\n",
      "\u001b[1;32m    179\u001b[0m         chat_history\u001b[38;5;241m=\u001b[39mchat_history,\n",
      "\u001b[1;32m    180\u001b[0m         settings\u001b[38;5;241m=\u001b[39mprompt_render_result\u001b[38;5;241m.\u001b[39mexecution_settings,\n",
      "\u001b[1;32m    181\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m\"\u001b[39m: context\u001b[38;5;241m.\u001b[39mkernel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marguments\u001b[39m\u001b[38;5;124m\"\u001b[39m: context\u001b[38;5;241m.\u001b[39marguments},\n",
      "\u001b[1;32m    182\u001b[0m     )\n",
      "\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/connectors/ai/chat_completion_client_base.py:139\u001b[0m, in \u001b[0;36mChatCompletionClientBase.get_chat_message_contents\u001b[0;34m(self, chat_history, settings, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m request_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(settings\u001b[38;5;241m.\u001b[39mfunction_choice_behavior\u001b[38;5;241m.\u001b[39mmaximum_auto_invoke_attempts):\n",
      "\u001b[0;32m--> 139\u001b[0m     completions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_get_chat_message_contents(chat_history, settings)\n",
      "\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# Get the function call contents from the chat message. There is only one chat message,\u001b[39;00m\n",
      "\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# which should be checked in the `_verify_function_choice_settings` method.\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/utils/telemetry/model_diagnostics/decorators.py:112\u001b[0m, in \u001b[0;36mtrace_chat_completion.<locals>.inner_trace_chat_completion.<locals>.wrapper_decorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m are_model_diagnostics_enabled():\n",
      "\u001b[1;32m    111\u001b[0m     \u001b[38;5;66;03m# If model diagnostics are not enabled, just return the completion\u001b[39;00m\n",
      "\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m completion_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;32m    114\u001b[0m completion_service: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatCompletionClientBase\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m]\n",
      "\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_chat_completion_base.py:88\u001b[0m, in \u001b[0;36mOpenAIChatCompletionBase._inner_get_chat_message_contents\u001b[0;34m(self, chat_history, settings)\u001b[0m\n",
      "\u001b[1;32m     86\u001b[0m settings\u001b[38;5;241m.\u001b[39mai_model_id \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mai_model_id \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mai_model_id\n",
      "\u001b[0;32m---> 88\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_request(settings)\n",
      "\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, ChatCompletion)  \u001b[38;5;66;03m# nosec\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_handler.py:60\u001b[0m, in \u001b[0;36mOpenAIHandler._send_request\u001b[0;34m(self, settings)\u001b[0m\n",
      "\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(settings, OpenAIPromptExecutionSettings)  \u001b[38;5;66;03m# nosec\u001b[39;00m\n",
      "\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_completion_request(settings)\n",
      "\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mai_model_type \u001b[38;5;241m==\u001b[39m OpenAIModelTypes\u001b[38;5;241m.\u001b[39mEMBEDDING:\n",
      "\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_handler.py:100\u001b[0m, in \u001b[0;36mOpenAIHandler._send_completion_request\u001b[0;34m(self, settings)\u001b[0m\n",
      "\u001b[1;32m     96\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ContentFilterAIException(\n",
      "\u001b[1;32m     97\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m service encountered a content error\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[1;32m     98\u001b[0m             ex,\n",
      "\u001b[1;32m     99\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mex\u001b[39;00m\n",
      "\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceResponseException(\n",
      "\u001b[1;32m    101\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m service failed to complete the prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[1;32m    102\u001b[0m         ex,\n",
      "\u001b[1;32m    103\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mex\u001b[39;00m\n",
      "\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "\n",
      "\u001b[0;31mServiceResponseException\u001b[0m: (\"<class 'semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion.AzureChatCompletion'> service failed to complete the prompt\", BadRequestError('Error code: 400 - {\\'error\\': {\\'message\\': \"Invalid parameter: \\'response_format\\' of type \\'json_schema\\' is not supported with this model. Learn more about supported models at the Structured Outputs guide: https://platform.openai.com/docs/guides/structured-outputs\", \\'type\\': \\'invalid_request_error\\', \\'param\\': None, \\'code\\': None}}'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[0;31mFunctionExecutionException\u001b[0m                Traceback (most recent call last)\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/agents/strategies/selection/kernel_function_selection_strategy.py:95\u001b[0m, in \u001b[0;36mKernelFunctionSelectionStrategy.select_agent\u001b[0;34m(self, agents, history)\u001b[0m\n",
      "\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m---> 95\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39minvoke(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel, arguments\u001b[38;5;241m=\u001b[39marguments)\n",
      "\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/functions/kernel_function.py:259\u001b[0m, in \u001b[0;36mKernelFunction.invoke\u001b[0;34m(self, kernel, arguments, metadata, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    258\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_exception(current_span, e, attributes)\n",
      "\u001b[0;32m--> 259\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/functions/kernel_function.py:251\u001b[0m, in \u001b[0;36mKernelFunction.invoke\u001b[0;34m(self, kernel, arguments, metadata, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    247\u001b[0m stack \u001b[38;5;241m=\u001b[39m kernel\u001b[38;5;241m.\u001b[39mconstruct_call_stack(\n",
      "\u001b[1;32m    248\u001b[0m     filter_type\u001b[38;5;241m=\u001b[39mFilterTypes\u001b[38;5;241m.\u001b[39mFUNCTION_INVOCATION,\n",
      "\u001b[1;32m    249\u001b[0m     inner_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invoke_internal,\n",
      "\u001b[1;32m    250\u001b[0m )\n",
      "\u001b[0;32m--> 251\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m stack(function_context)\n",
      "\u001b[1;32m    253\u001b[0m KernelFunctionLogMessages\u001b[38;5;241m.\u001b[39mlog_function_invoked_success(logger, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfully_qualified_name)\n",
      "\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/functions/kernel_function_from_prompt.py:184\u001b[0m, in \u001b[0;36mKernelFunctionFromPrompt._invoke_internal\u001b[0;34m(self, context)\u001b[0m\n",
      "\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[0;32m--> 184\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FunctionExecutionException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError occurred while invoking function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chat_message_contents:\n",
      "\n",
      "\u001b[0;31mFunctionExecutionException\u001b[0m: Error occurred while invoking function selection: (\"<class 'semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion.AzureChatCompletion'> service failed to complete the prompt\", BadRequestError('Error code: 400 - {\\'error\\': {\\'message\\': \"Invalid parameter: \\'response_format\\' of type \\'json_schema\\' is not supported with this model. Learn more about supported models at the Structured Outputs guide: https://platform.openai.com/docs/guides/structured-outputs\", \\'type\\': \\'invalid_request_error\\', \\'param\\': None, \\'code\\': None}}'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[0;31mAgentExecutionException\u001b[0m                   Traceback (most recent call last)\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/agents/group_chat/agent_group_chat.py:151\u001b[0m, in \u001b[0;36mAgentGroupChat.invoke\u001b[0;34m(self, agent, is_joining)\u001b[0m\n",
      "\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 151\u001b[0m     selected_agent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselection_strategy\u001b[38;5;241m.\u001b[39mnext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magents, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mmessages)\n",
      "\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/agents/strategies/selection/selection_strategy.py:43\u001b[0m, in \u001b[0;36mSelectionStrategy.next\u001b[0;34m(self, agents, history)\u001b[0m\n",
      "\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m---> 43\u001b[0m     agent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselect_agent(agents, history)\n",
      "\u001b[1;32m     45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_selected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/agents/strategies/selection/kernel_function_selection_strategy.py:98\u001b[0m, in \u001b[0;36mKernelFunctionSelectionStrategy.select_agent\u001b[0;34m(self, agents, history)\u001b[0m\n",
      "\u001b[1;32m     97\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKernel Function Selection Strategy next method failed\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39mex)\n",
      "\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m AgentExecutionException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgent Failure - Strategy failed to execute function.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mex\u001b[39;00m\n",
      "\u001b[1;32m    100\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\n",
      "\u001b[1;32m    101\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKernel Function Selection Strategy next method completed: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    102\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39mplugin_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, result: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mresult\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[1;32m    103\u001b[0m )\n",
      "\n",
      "\u001b[0;31mAgentExecutionException\u001b[0m: Agent Failure - Strategy failed to execute function.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[0;31mAgentChatException\u001b[0m                        Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m process_chat(chat, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOrchestrator: Prepare tumor board for Patient ID: patient_4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m, in \u001b[0;36mprocess_chat\u001b[0;34m(chat, user_message)\u001b[0m\n",
      "\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m chat\u001b[38;5;241m.\u001b[39madd_chat_message(ChatMessageContent(role\u001b[38;5;241m=\u001b[39mAuthorRole\u001b[38;5;241m.\u001b[39mUSER, content\u001b[38;5;241m=\u001b[39muser_message))\n",
      "\u001b[1;32m      9\u001b[0m chat\u001b[38;5;241m.\u001b[39mis_complete \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m chat\u001b[38;5;241m.\u001b[39minvoke():\n",
      "\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mrole\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mname\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chat\u001b[38;5;241m.\u001b[39mis_complete:\n",
      "\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/agents/group_chat/agent_group_chat.py:154\u001b[0m, in \u001b[0;36mAgentGroupChat.invoke\u001b[0;34m(self, agent, is_joining)\u001b[0m\n",
      "\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "\u001b[1;32m    153\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to select agent: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m AgentChatException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to select agent\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mex\u001b[39;00m\n",
      "\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39minvoke_agent(selected_agent):\n",
      "\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m message\u001b[38;5;241m.\u001b[39mrole \u001b[38;5;241m==\u001b[39m AuthorRole\u001b[38;5;241m.\u001b[39mASSISTANT:\n",
      "\n",
      "\u001b[0;31mAgentChatException\u001b[0m: Failed to select agent\n",
      "2025-08-08 13:24:27,160 - IPKernelApp - INFO - Exception in execute request:\n",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_handler.py:88\u001b[0m, in \u001b[0;36mOpenAIHandler._send_completion_request\u001b[0;34m(self, settings)\u001b[0m\n",
      "\u001b[1;32m     87\u001b[0m         settings_dict\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;32m---> 88\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msettings_dict)\n",
      "\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:2589\u001b[0m, in \u001b[0;36mAsyncCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n",
      "\u001b[1;32m   2588\u001b[0m validate_response_format(response_format)\n",
      "\u001b[0;32m-> 2589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n",
      "\u001b[1;32m   2590\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[1;32m   2591\u001b[0m     body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n",
      "\u001b[1;32m   2592\u001b[0m         {\n",
      "\u001b[1;32m   2593\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n",
      "\u001b[1;32m   2594\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n",
      "\u001b[1;32m   2595\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m: audio,\n",
      "\u001b[1;32m   2596\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n",
      "\u001b[1;32m   2597\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n",
      "\u001b[1;32m   2598\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n",
      "\u001b[1;32m   2599\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n",
      "\u001b[1;32m   2600\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n",
      "\u001b[1;32m   2601\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_completion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_completion_tokens,\n",
      "\u001b[1;32m   2602\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n",
      "\u001b[1;32m   2603\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n",
      "\u001b[1;32m   2604\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodalities\u001b[39m\u001b[38;5;124m\"\u001b[39m: modalities,\n",
      "\u001b[1;32m   2605\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n",
      "\u001b[1;32m   2606\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n",
      "\u001b[1;32m   2607\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m: prediction,\n",
      "\u001b[1;32m   2608\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n",
      "\u001b[1;32m   2609\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_cache_key\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt_cache_key,\n",
      "\u001b[1;32m   2610\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning_effort\u001b[39m\u001b[38;5;124m\"\u001b[39m: reasoning_effort,\n",
      "\u001b[1;32m   2611\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n",
      "\u001b[1;32m   2612\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msafety_identifier\u001b[39m\u001b[38;5;124m\"\u001b[39m: safety_identifier,\n",
      "\u001b[1;32m   2613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n",
      "\u001b[1;32m   2614\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n",
      "\u001b[1;32m   2615\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n",
      "\u001b[1;32m   2616\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m: store,\n",
      "\u001b[1;32m   2617\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n",
      "\u001b[1;32m   2618\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n",
      "\u001b[1;32m   2619\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n",
      "\u001b[1;32m   2620\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n",
      "\u001b[1;32m   2621\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n",
      "\u001b[1;32m   2622\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n",
      "\u001b[1;32m   2623\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n",
      "\u001b[1;32m   2624\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n",
      "\u001b[1;32m   2625\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbosity\u001b[39m\u001b[38;5;124m\"\u001b[39m: verbosity,\n",
      "\u001b[1;32m   2626\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweb_search_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: web_search_options,\n",
      "\u001b[1;32m   2627\u001b[0m         },\n",
      "\u001b[1;32m   2628\u001b[0m         completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParamsStreaming\n",
      "\u001b[1;32m   2629\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m stream\n",
      "\u001b[1;32m   2630\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParamsNonStreaming,\n",
      "\u001b[1;32m   2631\u001b[0m     ),\n",
      "\u001b[1;32m   2632\u001b[0m     options\u001b[38;5;241m=\u001b[39mmake_request_options(\n",
      "\u001b[1;32m   2633\u001b[0m         extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n",
      "\u001b[1;32m   2634\u001b[0m     ),\n",
      "\u001b[1;32m   2635\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n",
      "\u001b[1;32m   2636\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "\u001b[1;32m   2637\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mAsyncStream[ChatCompletionChunk],\n",
      "\u001b[1;32m   2638\u001b[0m )\n",
      "\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/openai/_base_client.py:1794\u001b[0m, in \u001b[0;36mAsyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[0m\n",
      "\u001b[1;32m   1791\u001b[0m opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n",
      "\u001b[1;32m   1792\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n",
      "\u001b[1;32m   1793\u001b[0m )\n",
      "\u001b[0;32m-> 1794\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls)\n",
      "\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/openai/_base_client.py:1594\u001b[0m, in \u001b[0;36mAsyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n",
      "\u001b[1;32m   1593\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;32m-> 1594\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m   1596\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_schema' is not supported with this model. Learn more about supported models at the Structured Outputs guide: https://platform.openai.com/docs/guides/structured-outputs\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[0;31mServiceResponseException\u001b[0m                  Traceback (most recent call last)\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/functions/kernel_function_from_prompt.py:178\u001b[0m, in \u001b[0;36mKernelFunctionFromPrompt._invoke_internal\u001b[0;34m(self, context)\u001b[0m\n",
      "\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 178\u001b[0m     chat_message_contents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m prompt_render_result\u001b[38;5;241m.\u001b[39mai_service\u001b[38;5;241m.\u001b[39mget_chat_message_contents(\n",
      "\u001b[1;32m    179\u001b[0m         chat_history\u001b[38;5;241m=\u001b[39mchat_history,\n",
      "\u001b[1;32m    180\u001b[0m         settings\u001b[38;5;241m=\u001b[39mprompt_render_result\u001b[38;5;241m.\u001b[39mexecution_settings,\n",
      "\u001b[1;32m    181\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m\"\u001b[39m: context\u001b[38;5;241m.\u001b[39mkernel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marguments\u001b[39m\u001b[38;5;124m\"\u001b[39m: context\u001b[38;5;241m.\u001b[39marguments},\n",
      "\u001b[1;32m    182\u001b[0m     )\n",
      "\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/connectors/ai/chat_completion_client_base.py:139\u001b[0m, in \u001b[0;36mChatCompletionClientBase.get_chat_message_contents\u001b[0;34m(self, chat_history, settings, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m request_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(settings\u001b[38;5;241m.\u001b[39mfunction_choice_behavior\u001b[38;5;241m.\u001b[39mmaximum_auto_invoke_attempts):\n",
      "\u001b[0;32m--> 139\u001b[0m     completions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_get_chat_message_contents(chat_history, settings)\n",
      "\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# Get the function call contents from the chat message. There is only one chat message,\u001b[39;00m\n",
      "\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# which should be checked in the `_verify_function_choice_settings` method.\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/utils/telemetry/model_diagnostics/decorators.py:112\u001b[0m, in \u001b[0;36mtrace_chat_completion.<locals>.inner_trace_chat_completion.<locals>.wrapper_decorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m are_model_diagnostics_enabled():\n",
      "\u001b[1;32m    111\u001b[0m     \u001b[38;5;66;03m# If model diagnostics are not enabled, just return the completion\u001b[39;00m\n",
      "\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m completion_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;32m    114\u001b[0m completion_service: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatCompletionClientBase\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m]\n",
      "\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_chat_completion_base.py:88\u001b[0m, in \u001b[0;36mOpenAIChatCompletionBase._inner_get_chat_message_contents\u001b[0;34m(self, chat_history, settings)\u001b[0m\n",
      "\u001b[1;32m     86\u001b[0m settings\u001b[38;5;241m.\u001b[39mai_model_id \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mai_model_id \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mai_model_id\n",
      "\u001b[0;32m---> 88\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_request(settings)\n",
      "\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, ChatCompletion)  \u001b[38;5;66;03m# nosec\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_handler.py:60\u001b[0m, in \u001b[0;36mOpenAIHandler._send_request\u001b[0;34m(self, settings)\u001b[0m\n",
      "\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(settings, OpenAIPromptExecutionSettings)  \u001b[38;5;66;03m# nosec\u001b[39;00m\n",
      "\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_completion_request(settings)\n",
      "\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mai_model_type \u001b[38;5;241m==\u001b[39m OpenAIModelTypes\u001b[38;5;241m.\u001b[39mEMBEDDING:\n",
      "\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_handler.py:100\u001b[0m, in \u001b[0;36mOpenAIHandler._send_completion_request\u001b[0;34m(self, settings)\u001b[0m\n",
      "\u001b[1;32m     96\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ContentFilterAIException(\n",
      "\u001b[1;32m     97\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m service encountered a content error\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[1;32m     98\u001b[0m             ex,\n",
      "\u001b[1;32m     99\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mex\u001b[39;00m\n",
      "\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceResponseException(\n",
      "\u001b[1;32m    101\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m service failed to complete the prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[1;32m    102\u001b[0m         ex,\n",
      "\u001b[1;32m    103\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mex\u001b[39;00m\n",
      "\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "\n",
      "\u001b[0;31mServiceResponseException\u001b[0m: (\"<class 'semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion.AzureChatCompletion'> service failed to complete the prompt\", BadRequestError('Error code: 400 - {\\'error\\': {\\'message\\': \"Invalid parameter: \\'response_format\\' of type \\'json_schema\\' is not supported with this model. Learn more about supported models at the Structured Outputs guide: https://platform.openai.com/docs/guides/structured-outputs\", \\'type\\': \\'invalid_request_error\\', \\'param\\': None, \\'code\\': None}}'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[0;31mFunctionExecutionException\u001b[0m                Traceback (most recent call last)\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/agents/strategies/selection/kernel_function_selection_strategy.py:95\u001b[0m, in \u001b[0;36mKernelFunctionSelectionStrategy.select_agent\u001b[0;34m(self, agents, history)\u001b[0m\n",
      "\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m---> 95\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39minvoke(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel, arguments\u001b[38;5;241m=\u001b[39marguments)\n",
      "\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/functions/kernel_function.py:259\u001b[0m, in \u001b[0;36mKernelFunction.invoke\u001b[0;34m(self, kernel, arguments, metadata, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    258\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_exception(current_span, e, attributes)\n",
      "\u001b[0;32m--> 259\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/functions/kernel_function.py:251\u001b[0m, in \u001b[0;36mKernelFunction.invoke\u001b[0;34m(self, kernel, arguments, metadata, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    247\u001b[0m stack \u001b[38;5;241m=\u001b[39m kernel\u001b[38;5;241m.\u001b[39mconstruct_call_stack(\n",
      "\u001b[1;32m    248\u001b[0m     filter_type\u001b[38;5;241m=\u001b[39mFilterTypes\u001b[38;5;241m.\u001b[39mFUNCTION_INVOCATION,\n",
      "\u001b[1;32m    249\u001b[0m     inner_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invoke_internal,\n",
      "\u001b[1;32m    250\u001b[0m )\n",
      "\u001b[0;32m--> 251\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m stack(function_context)\n",
      "\u001b[1;32m    253\u001b[0m KernelFunctionLogMessages\u001b[38;5;241m.\u001b[39mlog_function_invoked_success(logger, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfully_qualified_name)\n",
      "\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/functions/kernel_function_from_prompt.py:184\u001b[0m, in \u001b[0;36mKernelFunctionFromPrompt._invoke_internal\u001b[0;34m(self, context)\u001b[0m\n",
      "\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[0;32m--> 184\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FunctionExecutionException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError occurred while invoking function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chat_message_contents:\n",
      "\n",
      "\u001b[0;31mFunctionExecutionException\u001b[0m: Error occurred while invoking function selection: (\"<class 'semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion.AzureChatCompletion'> service failed to complete the prompt\", BadRequestError('Error code: 400 - {\\'error\\': {\\'message\\': \"Invalid parameter: \\'response_format\\' of type \\'json_schema\\' is not supported with this model. Learn more about supported models at the Structured Outputs guide: https://platform.openai.com/docs/guides/structured-outputs\", \\'type\\': \\'invalid_request_error\\', \\'param\\': None, \\'code\\': None}}'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[0;31mAgentExecutionException\u001b[0m                   Traceback (most recent call last)\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/agents/group_chat/agent_group_chat.py:151\u001b[0m, in \u001b[0;36mAgentGroupChat.invoke\u001b[0;34m(self, agent, is_joining)\u001b[0m\n",
      "\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 151\u001b[0m     selected_agent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselection_strategy\u001b[38;5;241m.\u001b[39mnext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magents, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mmessages)\n",
      "\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/agents/strategies/selection/selection_strategy.py:43\u001b[0m, in \u001b[0;36mSelectionStrategy.next\u001b[0;34m(self, agents, history)\u001b[0m\n",
      "\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m---> 43\u001b[0m     agent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselect_agent(agents, history)\n",
      "\u001b[1;32m     45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_selected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/agents/strategies/selection/kernel_function_selection_strategy.py:98\u001b[0m, in \u001b[0;36mKernelFunctionSelectionStrategy.select_agent\u001b[0;34m(self, agents, history)\u001b[0m\n",
      "\u001b[1;32m     97\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKernel Function Selection Strategy next method failed\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39mex)\n",
      "\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m AgentExecutionException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgent Failure - Strategy failed to execute function.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mex\u001b[39;00m\n",
      "\u001b[1;32m    100\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\n",
      "\u001b[1;32m    101\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKernel Function Selection Strategy next method completed: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    102\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39mplugin_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, result: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mresult\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[1;32m    103\u001b[0m )\n",
      "\n",
      "\u001b[0;31mAgentExecutionException\u001b[0m: Agent Failure - Strategy failed to execute function.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[0;31mAgentChatException\u001b[0m                        Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m process_chat(chat, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOrchestrator: Prepare tumor board for Patient ID: patient_4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m, in \u001b[0;36mprocess_chat\u001b[0;34m(chat, user_message)\u001b[0m\n",
      "\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m chat\u001b[38;5;241m.\u001b[39madd_chat_message(ChatMessageContent(role\u001b[38;5;241m=\u001b[39mAuthorRole\u001b[38;5;241m.\u001b[39mUSER, content\u001b[38;5;241m=\u001b[39muser_message))\n",
      "\u001b[1;32m      9\u001b[0m chat\u001b[38;5;241m.\u001b[39mis_complete \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m chat\u001b[38;5;241m.\u001b[39minvoke():\n",
      "\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mrole\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mname\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chat\u001b[38;5;241m.\u001b[39mis_complete:\n",
      "\n",
      "File \u001b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/agents/group_chat/agent_group_chat.py:154\u001b[0m, in \u001b[0;36mAgentGroupChat.invoke\u001b[0;34m(self, agent, is_joining)\u001b[0m\n",
      "\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "\u001b[1;32m    153\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to select agent: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m AgentChatException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to select agent\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mex\u001b[39;00m\n",
      "\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39minvoke_agent(selected_agent):\n",
      "\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m message\u001b[38;5;241m.\u001b[39mrole \u001b[38;5;241m==\u001b[39m AuthorRole\u001b[38;5;241m.\u001b[39mASSISTANT:\n",
      "\n",
      "\u001b[0;31mAgentChatException\u001b[0m: Failed to select agent\n",
      "2025-08-08 13:24:27,164 - IPKernelApp - DEBUG - {'header': {'msg_id': '571bc763-22923a1b7e800ab4f182ecfe_58456_118', 'msg_type': 'execute_reply', 'username': 'mablonde', 'session': '571bc763-22923a1b7e800ab4f182ecfe', 'date': datetime.datetime(2025, 8, 8, 20, 24, 27, 164489, tzinfo=datetime.timezone.utc), 'version': '5.3'}, 'msg_id': '571bc763-22923a1b7e800ab4f182ecfe_58456_118', 'msg_type': 'execute_reply', 'parent_header': {'date': datetime.datetime(2025, 8, 8, 20, 24, 24, 899000, tzinfo=tzutc()), 'msg_id': '8bff73fc-2beb-4dfb-92c7-172c72498c0b', 'msg_type': 'execute_request', 'session': '00adb0ca-9d5f-4df4-b793-380b7a539da0', 'username': '8dc24feb-2c65-412a-9798-1ee6e8d34202', 'version': '5.2'}, 'content': {'status': 'error', 'traceback': ['\\x1b[0;31m---------------------------------------------------------------------------\\x1b[0m', '\\x1b[0;31mBadRequestError\\x1b[0m                           Traceback (most recent call last)', 'File \\x1b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_handler.py:88\\x1b[0m, in \\x1b[0;36mOpenAIHandler._send_completion_request\\x1b[0;34m(self, settings)\\x1b[0m\\n\\x1b[1;32m     87\\x1b[0m         settings_dict\\x1b[38;5;241m.\\x1b[39mpop(\\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mparallel_tool_calls\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m, \\x1b[38;5;28;01mNone\\x1b[39;00m)\\n\\x1b[0;32m---> 88\\x1b[0m     response \\x1b[38;5;241m=\\x1b[39m \\x1b[38;5;28;01mawait\\x1b[39;00m \\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39mclient\\x1b[38;5;241m.\\x1b[39mchat\\x1b[38;5;241m.\\x1b[39mcompletions\\x1b[38;5;241m.\\x1b[39mcreate(\\x1b[38;5;241m*\\x1b[39m\\x1b[38;5;241m*\\x1b[39msettings_dict)\\n\\x1b[1;32m     89\\x1b[0m \\x1b[38;5;28;01melse\\x1b[39;00m:\\n', 'File \\x1b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:2589\\x1b[0m, in \\x1b[0;36mAsyncCompletions.create\\x1b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\\x1b[0m\\n\\x1b[1;32m   2588\\x1b[0m validate_response_format(response_format)\\n\\x1b[0;32m-> 2589\\x1b[0m \\x1b[38;5;28;01mreturn\\x1b[39;00m \\x1b[38;5;28;01mawait\\x1b[39;00m \\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39m_post(\\n\\x1b[1;32m   2590\\x1b[0m     \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124m/chat/completions\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m,\\n\\x1b[1;32m   2591\\x1b[0m     body\\x1b[38;5;241m=\\x1b[39m\\x1b[38;5;28;01mawait\\x1b[39;00m async_maybe_transform(\\n\\x1b[1;32m   2592\\x1b[0m         {\\n\\x1b[1;32m   2593\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mmessages\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: messages,\\n\\x1b[1;32m   2594\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mmodel\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: model,\\n\\x1b[1;32m   2595\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124maudio\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: audio,\\n\\x1b[1;32m   2596\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mfrequency_penalty\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: frequency_penalty,\\n\\x1b[1;32m   2597\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mfunction_call\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: function_call,\\n\\x1b[1;32m   2598\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mfunctions\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: functions,\\n\\x1b[1;32m   2599\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mlogit_bias\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: logit_bias,\\n\\x1b[1;32m   2600\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mlogprobs\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: logprobs,\\n\\x1b[1;32m   2601\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mmax_completion_tokens\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: max_completion_tokens,\\n\\x1b[1;32m   2602\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mmax_tokens\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: max_tokens,\\n\\x1b[1;32m   2603\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mmetadata\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: metadata,\\n\\x1b[1;32m   2604\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mmodalities\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: modalities,\\n\\x1b[1;32m   2605\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mn\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: n,\\n\\x1b[1;32m   2606\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mparallel_tool_calls\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: parallel_tool_calls,\\n\\x1b[1;32m   2607\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mprediction\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: prediction,\\n\\x1b[1;32m   2608\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mpresence_penalty\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: presence_penalty,\\n\\x1b[1;32m   2609\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mprompt_cache_key\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: prompt_cache_key,\\n\\x1b[1;32m   2610\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mreasoning_effort\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: reasoning_effort,\\n\\x1b[1;32m   2611\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mresponse_format\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: response_format,\\n\\x1b[1;32m   2612\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124msafety_identifier\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: safety_identifier,\\n\\x1b[1;32m   2613\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mseed\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: seed,\\n\\x1b[1;32m   2614\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mservice_tier\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: service_tier,\\n\\x1b[1;32m   2615\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mstop\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: stop,\\n\\x1b[1;32m   2616\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mstore\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: store,\\n\\x1b[1;32m   2617\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mstream\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: stream,\\n\\x1b[1;32m   2618\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mstream_options\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: stream_options,\\n\\x1b[1;32m   2619\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mtemperature\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: temperature,\\n\\x1b[1;32m   2620\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mtool_choice\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: tool_choice,\\n\\x1b[1;32m   2621\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mtools\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: tools,\\n\\x1b[1;32m   2622\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mtop_logprobs\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: top_logprobs,\\n\\x1b[1;32m   2623\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mtop_p\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: top_p,\\n\\x1b[1;32m   2624\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124muser\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: user,\\n\\x1b[1;32m   2625\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mverbosity\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: verbosity,\\n\\x1b[1;32m   2626\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mweb_search_options\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: web_search_options,\\n\\x1b[1;32m   2627\\x1b[0m         },\\n\\x1b[1;32m   2628\\x1b[0m         completion_create_params\\x1b[38;5;241m.\\x1b[39mCompletionCreateParamsStreaming\\n\\x1b[1;32m   2629\\x1b[0m         \\x1b[38;5;28;01mif\\x1b[39;00m stream\\n\\x1b[1;32m   2630\\x1b[0m         \\x1b[38;5;28;01melse\\x1b[39;00m completion_create_params\\x1b[38;5;241m.\\x1b[39mCompletionCreateParamsNonStreaming,\\n\\x1b[1;32m   2631\\x1b[0m     ),\\n\\x1b[1;32m   2632\\x1b[0m     options\\x1b[38;5;241m=\\x1b[39mmake_request_options(\\n\\x1b[1;32m   2633\\x1b[0m         extra_headers\\x1b[38;5;241m=\\x1b[39mextra_headers, extra_query\\x1b[38;5;241m=\\x1b[39mextra_query, extra_body\\x1b[38;5;241m=\\x1b[39mextra_body, timeout\\x1b[38;5;241m=\\x1b[39mtimeout\\n\\x1b[1;32m   2634\\x1b[0m     ),\\n\\x1b[1;32m   2635\\x1b[0m     cast_to\\x1b[38;5;241m=\\x1b[39mChatCompletion,\\n\\x1b[1;32m   2636\\x1b[0m     stream\\x1b[38;5;241m=\\x1b[39mstream \\x1b[38;5;129;01mor\\x1b[39;00m \\x1b[38;5;28;01mFalse\\x1b[39;00m,\\n\\x1b[1;32m   2637\\x1b[0m     stream_cls\\x1b[38;5;241m=\\x1b[39mAsyncStream[ChatCompletionChunk],\\n\\x1b[1;32m   2638\\x1b[0m )\\n', 'File \\x1b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/openai/_base_client.py:1794\\x1b[0m, in \\x1b[0;36mAsyncAPIClient.post\\x1b[0;34m(self, path, cast_to, body, files, options, stream, stream_cls)\\x1b[0m\\n\\x1b[1;32m   1791\\x1b[0m opts \\x1b[38;5;241m=\\x1b[39m FinalRequestOptions\\x1b[38;5;241m.\\x1b[39mconstruct(\\n\\x1b[1;32m   1792\\x1b[0m     method\\x1b[38;5;241m=\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mpost\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m, url\\x1b[38;5;241m=\\x1b[39mpath, json_data\\x1b[38;5;241m=\\x1b[39mbody, files\\x1b[38;5;241m=\\x1b[39m\\x1b[38;5;28;01mawait\\x1b[39;00m async_to_httpx_files(files), \\x1b[38;5;241m*\\x1b[39m\\x1b[38;5;241m*\\x1b[39moptions\\n\\x1b[1;32m   1793\\x1b[0m )\\n\\x1b[0;32m-> 1794\\x1b[0m \\x1b[38;5;28;01mreturn\\x1b[39;00m \\x1b[38;5;28;01mawait\\x1b[39;00m \\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39mrequest(cast_to, opts, stream\\x1b[38;5;241m=\\x1b[39mstream, stream_cls\\x1b[38;5;241m=\\x1b[39mstream_cls)\\n', 'File \\x1b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/openai/_base_client.py:1594\\x1b[0m, in \\x1b[0;36mAsyncAPIClient.request\\x1b[0;34m(self, cast_to, options, stream, stream_cls)\\x1b[0m\\n\\x1b[1;32m   1593\\x1b[0m     log\\x1b[38;5;241m.\\x1b[39mdebug(\\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mRe-raising status error\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m)\\n\\x1b[0;32m-> 1594\\x1b[0m     \\x1b[38;5;28;01mraise\\x1b[39;00m \\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39m_make_status_error_from_response(err\\x1b[38;5;241m.\\x1b[39mresponse) \\x1b[38;5;28;01mfrom\\x1b[39;00m\\x1b[38;5;250m \\x1b[39m\\x1b[38;5;28;01mNone\\x1b[39;00m\\n\\x1b[1;32m   1596\\x1b[0m \\x1b[38;5;28;01mbreak\\x1b[39;00m\\n', '\\x1b[0;31mBadRequestError\\x1b[0m: Error code: 400 - {\\'error\\': {\\'message\\': \"Invalid parameter: \\'response_format\\' of type \\'json_schema\\' is not supported with this model. Learn more about supported models at the Structured Outputs guide: https://platform.openai.com/docs/guides/structured-outputs\", \\'type\\': \\'invalid_request_error\\', \\'param\\': None, \\'code\\': None}}', '\\nThe above exception was the direct cause of the following exception:\\n', '\\x1b[0;31mServiceResponseException\\x1b[0m                  Traceback (most recent call last)', 'File \\x1b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/functions/kernel_function_from_prompt.py:178\\x1b[0m, in \\x1b[0;36mKernelFunctionFromPrompt._invoke_internal\\x1b[0;34m(self, context)\\x1b[0m\\n\\x1b[1;32m    177\\x1b[0m \\x1b[38;5;28;01mtry\\x1b[39;00m:\\n\\x1b[0;32m--> 178\\x1b[0m     chat_message_contents \\x1b[38;5;241m=\\x1b[39m \\x1b[38;5;28;01mawait\\x1b[39;00m prompt_render_result\\x1b[38;5;241m.\\x1b[39mai_service\\x1b[38;5;241m.\\x1b[39mget_chat_message_contents(\\n\\x1b[1;32m    179\\x1b[0m         chat_history\\x1b[38;5;241m=\\x1b[39mchat_history,\\n\\x1b[1;32m    180\\x1b[0m         settings\\x1b[38;5;241m=\\x1b[39mprompt_render_result\\x1b[38;5;241m.\\x1b[39mexecution_settings,\\n\\x1b[1;32m    181\\x1b[0m         \\x1b[38;5;241m*\\x1b[39m\\x1b[38;5;241m*\\x1b[39m{\\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mkernel\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: context\\x1b[38;5;241m.\\x1b[39mkernel, \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124marguments\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: context\\x1b[38;5;241m.\\x1b[39marguments},\\n\\x1b[1;32m    182\\x1b[0m     )\\n\\x1b[1;32m    183\\x1b[0m \\x1b[38;5;28;01mexcept\\x1b[39;00m \\x1b[38;5;167;01mException\\x1b[39;00m \\x1b[38;5;28;01mas\\x1b[39;00m exc:\\n', 'File \\x1b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/connectors/ai/chat_completion_client_base.py:139\\x1b[0m, in \\x1b[0;36mChatCompletionClientBase.get_chat_message_contents\\x1b[0;34m(self, chat_history, settings, **kwargs)\\x1b[0m\\n\\x1b[1;32m    138\\x1b[0m \\x1b[38;5;28;01mfor\\x1b[39;00m request_index \\x1b[38;5;129;01min\\x1b[39;00m \\x1b[38;5;28mrange\\x1b[39m(settings\\x1b[38;5;241m.\\x1b[39mfunction_choice_behavior\\x1b[38;5;241m.\\x1b[39mmaximum_auto_invoke_attempts):\\n\\x1b[0;32m--> 139\\x1b[0m     completions \\x1b[38;5;241m=\\x1b[39m \\x1b[38;5;28;01mawait\\x1b[39;00m \\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39m_inner_get_chat_message_contents(chat_history, settings)\\n\\x1b[1;32m    140\\x1b[0m     \\x1b[38;5;66;03m# Get the function call contents from the chat message. There is only one chat message,\\x1b[39;00m\\n\\x1b[1;32m    141\\x1b[0m     \\x1b[38;5;66;03m# which should be checked in the `_verify_function_choice_settings` method.\\x1b[39;00m\\n', 'File \\x1b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/utils/telemetry/model_diagnostics/decorators.py:112\\x1b[0m, in \\x1b[0;36mtrace_chat_completion.<locals>.inner_trace_chat_completion.<locals>.wrapper_decorator\\x1b[0;34m(*args, **kwargs)\\x1b[0m\\n\\x1b[1;32m    110\\x1b[0m \\x1b[38;5;28;01mif\\x1b[39;00m \\x1b[38;5;129;01mnot\\x1b[39;00m are_model_diagnostics_enabled():\\n\\x1b[1;32m    111\\x1b[0m     \\x1b[38;5;66;03m# If model diagnostics are not enabled, just return the completion\\x1b[39;00m\\n\\x1b[0;32m--> 112\\x1b[0m     \\x1b[38;5;28;01mreturn\\x1b[39;00m \\x1b[38;5;28;01mawait\\x1b[39;00m completion_func(\\x1b[38;5;241m*\\x1b[39margs, \\x1b[38;5;241m*\\x1b[39m\\x1b[38;5;241m*\\x1b[39mkwargs)\\n\\x1b[1;32m    114\\x1b[0m completion_service: \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mChatCompletionClientBase\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m \\x1b[38;5;241m=\\x1b[39m args[\\x1b[38;5;241m0\\x1b[39m]\\n', 'File \\x1b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_chat_completion_base.py:88\\x1b[0m, in \\x1b[0;36mOpenAIChatCompletionBase._inner_get_chat_message_contents\\x1b[0;34m(self, chat_history, settings)\\x1b[0m\\n\\x1b[1;32m     86\\x1b[0m settings\\x1b[38;5;241m.\\x1b[39mai_model_id \\x1b[38;5;241m=\\x1b[39m settings\\x1b[38;5;241m.\\x1b[39mai_model_id \\x1b[38;5;129;01mor\\x1b[39;00m \\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39mai_model_id\\n\\x1b[0;32m---> 88\\x1b[0m response \\x1b[38;5;241m=\\x1b[39m \\x1b[38;5;28;01mawait\\x1b[39;00m \\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39m_send_request(settings)\\n\\x1b[1;32m     89\\x1b[0m \\x1b[38;5;28;01massert\\x1b[39;00m \\x1b[38;5;28misinstance\\x1b[39m(response, ChatCompletion)  \\x1b[38;5;66;03m# nosec\\x1b[39;00m\\n', 'File \\x1b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_handler.py:60\\x1b[0m, in \\x1b[0;36mOpenAIHandler._send_request\\x1b[0;34m(self, settings)\\x1b[0m\\n\\x1b[1;32m     59\\x1b[0m     \\x1b[38;5;28;01massert\\x1b[39;00m \\x1b[38;5;28misinstance\\x1b[39m(settings, OpenAIPromptExecutionSettings)  \\x1b[38;5;66;03m# nosec\\x1b[39;00m\\n\\x1b[0;32m---> 60\\x1b[0m     \\x1b[38;5;28;01mreturn\\x1b[39;00m \\x1b[38;5;28;01mawait\\x1b[39;00m \\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39m_send_completion_request(settings)\\n\\x1b[1;32m     61\\x1b[0m \\x1b[38;5;28;01mif\\x1b[39;00m \\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39mai_model_type \\x1b[38;5;241m==\\x1b[39m OpenAIModelTypes\\x1b[38;5;241m.\\x1b[39mEMBEDDING:\\n', 'File \\x1b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_handler.py:100\\x1b[0m, in \\x1b[0;36mOpenAIHandler._send_completion_request\\x1b[0;34m(self, settings)\\x1b[0m\\n\\x1b[1;32m     96\\x1b[0m         \\x1b[38;5;28;01mraise\\x1b[39;00m ContentFilterAIException(\\n\\x1b[1;32m     97\\x1b[0m             \\x1b[38;5;124mf\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;132;01m{\\x1b[39;00m\\x1b[38;5;28mtype\\x1b[39m(\\x1b[38;5;28mself\\x1b[39m)\\x1b[38;5;132;01m}\\x1b[39;00m\\x1b[38;5;124m service encountered a content error\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m,\\n\\x1b[1;32m     98\\x1b[0m             ex,\\n\\x1b[1;32m     99\\x1b[0m         ) \\x1b[38;5;28;01mfrom\\x1b[39;00m\\x1b[38;5;250m \\x1b[39m\\x1b[38;5;21;01mex\\x1b[39;00m\\n\\x1b[0;32m--> 100\\x1b[0m     \\x1b[38;5;28;01mraise\\x1b[39;00m ServiceResponseException(\\n\\x1b[1;32m    101\\x1b[0m         \\x1b[38;5;124mf\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;132;01m{\\x1b[39;00m\\x1b[38;5;28mtype\\x1b[39m(\\x1b[38;5;28mself\\x1b[39m)\\x1b[38;5;132;01m}\\x1b[39;00m\\x1b[38;5;124m service failed to complete the prompt\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m,\\n\\x1b[1;32m    102\\x1b[0m         ex,\\n\\x1b[1;32m    103\\x1b[0m     ) \\x1b[38;5;28;01mfrom\\x1b[39;00m\\x1b[38;5;250m \\x1b[39m\\x1b[38;5;21;01mex\\x1b[39;00m\\n\\x1b[1;32m    104\\x1b[0m \\x1b[38;5;28;01mexcept\\x1b[39;00m \\x1b[38;5;167;01mException\\x1b[39;00m \\x1b[38;5;28;01mas\\x1b[39;00m ex:\\n', '\\x1b[0;31mServiceResponseException\\x1b[0m: (\"<class \\'semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion.AzureChatCompletion\\'> service failed to complete the prompt\", BadRequestError(\\'Error code: 400 - {\\\\\\'error\\\\\\': {\\\\\\'message\\\\\\': \"Invalid parameter: \\\\\\'response_format\\\\\\' of type \\\\\\'json_schema\\\\\\' is not supported with this model. Learn more about supported models at the Structured Outputs guide: https://platform.openai.com/docs/guides/structured-outputs\", \\\\\\'type\\\\\\': \\\\\\'invalid_request_error\\\\\\', \\\\\\'param\\\\\\': None, \\\\\\'code\\\\\\': None}}\\'))', '\\nThe above exception was the direct cause of the following exception:\\n', '\\x1b[0;31mFunctionExecutionException\\x1b[0m                Traceback (most recent call last)', 'File \\x1b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/agents/strategies/selection/kernel_function_selection_strategy.py:95\\x1b[0m, in \\x1b[0;36mKernelFunctionSelectionStrategy.select_agent\\x1b[0;34m(self, agents, history)\\x1b[0m\\n\\x1b[1;32m     94\\x1b[0m \\x1b[38;5;28;01mtry\\x1b[39;00m:\\n\\x1b[0;32m---> 95\\x1b[0m     result \\x1b[38;5;241m=\\x1b[39m \\x1b[38;5;28;01mawait\\x1b[39;00m \\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39mfunction\\x1b[38;5;241m.\\x1b[39minvoke(kernel\\x1b[38;5;241m=\\x1b[39m\\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39mkernel, arguments\\x1b[38;5;241m=\\x1b[39marguments)\\n\\x1b[1;32m     96\\x1b[0m \\x1b[38;5;28;01mexcept\\x1b[39;00m \\x1b[38;5;167;01mException\\x1b[39;00m \\x1b[38;5;28;01mas\\x1b[39;00m ex:\\n', 'File \\x1b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/functions/kernel_function.py:259\\x1b[0m, in \\x1b[0;36mKernelFunction.invoke\\x1b[0;34m(self, kernel, arguments, metadata, **kwargs)\\x1b[0m\\n\\x1b[1;32m    258\\x1b[0m     \\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39m_handle_exception(current_span, e, attributes)\\n\\x1b[0;32m--> 259\\x1b[0m     \\x1b[38;5;28;01mraise\\x1b[39;00m e\\n\\x1b[1;32m    260\\x1b[0m \\x1b[38;5;28;01mfinally\\x1b[39;00m:\\n', 'File \\x1b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/functions/kernel_function.py:251\\x1b[0m, in \\x1b[0;36mKernelFunction.invoke\\x1b[0;34m(self, kernel, arguments, metadata, **kwargs)\\x1b[0m\\n\\x1b[1;32m    247\\x1b[0m stack \\x1b[38;5;241m=\\x1b[39m kernel\\x1b[38;5;241m.\\x1b[39mconstruct_call_stack(\\n\\x1b[1;32m    248\\x1b[0m     filter_type\\x1b[38;5;241m=\\x1b[39mFilterTypes\\x1b[38;5;241m.\\x1b[39mFUNCTION_INVOCATION,\\n\\x1b[1;32m    249\\x1b[0m     inner_function\\x1b[38;5;241m=\\x1b[39m\\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39m_invoke_internal,\\n\\x1b[1;32m    250\\x1b[0m )\\n\\x1b[0;32m--> 251\\x1b[0m \\x1b[38;5;28;01mawait\\x1b[39;00m stack(function_context)\\n\\x1b[1;32m    253\\x1b[0m KernelFunctionLogMessages\\x1b[38;5;241m.\\x1b[39mlog_function_invoked_success(logger, \\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39mfully_qualified_name)\\n', 'File \\x1b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/functions/kernel_function_from_prompt.py:184\\x1b[0m, in \\x1b[0;36mKernelFunctionFromPrompt._invoke_internal\\x1b[0;34m(self, context)\\x1b[0m\\n\\x1b[1;32m    183\\x1b[0m \\x1b[38;5;28;01mexcept\\x1b[39;00m \\x1b[38;5;167;01mException\\x1b[39;00m \\x1b[38;5;28;01mas\\x1b[39;00m exc:\\n\\x1b[0;32m--> 184\\x1b[0m     \\x1b[38;5;28;01mraise\\x1b[39;00m FunctionExecutionException(\\x1b[38;5;124mf\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mError occurred while invoking function \\x1b[39m\\x1b[38;5;132;01m{\\x1b[39;00m\\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39mname\\x1b[38;5;132;01m}\\x1b[39;00m\\x1b[38;5;124m: \\x1b[39m\\x1b[38;5;132;01m{\\x1b[39;00mexc\\x1b[38;5;132;01m}\\x1b[39;00m\\x1b[38;5;124m\"\\x1b[39m) \\x1b[38;5;28;01mfrom\\x1b[39;00m\\x1b[38;5;250m \\x1b[39m\\x1b[38;5;21;01mexc\\x1b[39;00m\\n\\x1b[1;32m    186\\x1b[0m \\x1b[38;5;28;01mif\\x1b[39;00m \\x1b[38;5;129;01mnot\\x1b[39;00m chat_message_contents:\\n', '\\x1b[0;31mFunctionExecutionException\\x1b[0m: Error occurred while invoking function selection: (\"<class \\'semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion.AzureChatCompletion\\'> service failed to complete the prompt\", BadRequestError(\\'Error code: 400 - {\\\\\\'error\\\\\\': {\\\\\\'message\\\\\\': \"Invalid parameter: \\\\\\'response_format\\\\\\' of type \\\\\\'json_schema\\\\\\' is not supported with this model. Learn more about supported models at the Structured Outputs guide: https://platform.openai.com/docs/guides/structured-outputs\", \\\\\\'type\\\\\\': \\\\\\'invalid_request_error\\\\\\', \\\\\\'param\\\\\\': None, \\\\\\'code\\\\\\': None}}\\'))', '\\nThe above exception was the direct cause of the following exception:\\n', '\\x1b[0;31mAgentExecutionException\\x1b[0m                   Traceback (most recent call last)', 'File \\x1b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/agents/group_chat/agent_group_chat.py:151\\x1b[0m, in \\x1b[0;36mAgentGroupChat.invoke\\x1b[0;34m(self, agent, is_joining)\\x1b[0m\\n\\x1b[1;32m    150\\x1b[0m \\x1b[38;5;28;01mtry\\x1b[39;00m:\\n\\x1b[0;32m--> 151\\x1b[0m     selected_agent \\x1b[38;5;241m=\\x1b[39m \\x1b[38;5;28;01mawait\\x1b[39;00m \\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39mselection_strategy\\x1b[38;5;241m.\\x1b[39mnext(\\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39magents, \\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39mhistory\\x1b[38;5;241m.\\x1b[39mmessages)\\n\\x1b[1;32m    152\\x1b[0m \\x1b[38;5;28;01mexcept\\x1b[39;00m \\x1b[38;5;167;01mException\\x1b[39;00m \\x1b[38;5;28;01mas\\x1b[39;00m ex:\\n', 'File \\x1b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/agents/strategies/selection/selection_strategy.py:43\\x1b[0m, in \\x1b[0;36mSelectionStrategy.next\\x1b[0;34m(self, agents, history)\\x1b[0m\\n\\x1b[1;32m     42\\x1b[0m \\x1b[38;5;28;01melse\\x1b[39;00m:\\n\\x1b[0;32m---> 43\\x1b[0m     agent \\x1b[38;5;241m=\\x1b[39m \\x1b[38;5;28;01mawait\\x1b[39;00m \\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39mselect_agent(agents, history)\\n\\x1b[1;32m     45\\x1b[0m \\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39mhas_selected \\x1b[38;5;241m=\\x1b[39m \\x1b[38;5;28;01mTrue\\x1b[39;00m\\n', 'File \\x1b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/agents/strategies/selection/kernel_function_selection_strategy.py:98\\x1b[0m, in \\x1b[0;36mKernelFunctionSelectionStrategy.select_agent\\x1b[0;34m(self, agents, history)\\x1b[0m\\n\\x1b[1;32m     97\\x1b[0m     logger\\x1b[38;5;241m.\\x1b[39merror(\\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mKernel Function Selection Strategy next method failed\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m, exc_info\\x1b[38;5;241m=\\x1b[39mex)\\n\\x1b[0;32m---> 98\\x1b[0m     \\x1b[38;5;28;01mraise\\x1b[39;00m AgentExecutionException(\\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mAgent Failure - Strategy failed to execute function.\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m) \\x1b[38;5;28;01mfrom\\x1b[39;00m\\x1b[38;5;250m \\x1b[39m\\x1b[38;5;21;01mex\\x1b[39;00m\\n\\x1b[1;32m    100\\x1b[0m logger\\x1b[38;5;241m.\\x1b[39minfo(\\n\\x1b[1;32m    101\\x1b[0m     \\x1b[38;5;124mf\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mKernel Function Selection Strategy next method completed: \\x1b[39m\\x1b[38;5;124m\"\\x1b[39m\\n\\x1b[1;32m    102\\x1b[0m     \\x1b[38;5;124mf\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;132;01m{\\x1b[39;00m\\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39mfunction\\x1b[38;5;241m.\\x1b[39mplugin_name\\x1b[38;5;132;01m}\\x1b[39;00m\\x1b[38;5;124m, \\x1b[39m\\x1b[38;5;132;01m{\\x1b[39;00m\\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39mfunction\\x1b[38;5;241m.\\x1b[39mname\\x1b[38;5;132;01m}\\x1b[39;00m\\x1b[38;5;124m, result: \\x1b[39m\\x1b[38;5;132;01m{\\x1b[39;00mresult\\x1b[38;5;241m.\\x1b[39mvalue\\x1b[38;5;250m \\x1b[39m\\x1b[38;5;28;01mif\\x1b[39;00m\\x1b[38;5;250m \\x1b[39mresult\\x1b[38;5;250m \\x1b[39m\\x1b[38;5;28;01melse\\x1b[39;00m\\x1b[38;5;250m \\x1b[39m\\x1b[38;5;28;01mNone\\x1b[39;00m\\x1b[38;5;132;01m}\\x1b[39;00m\\x1b[38;5;124m\"\\x1b[39m,\\n\\x1b[1;32m    103\\x1b[0m )\\n', '\\x1b[0;31mAgentExecutionException\\x1b[0m: Agent Failure - Strategy failed to execute function.', '\\nThe above exception was the direct cause of the following exception:\\n', '\\x1b[0;31mAgentChatException\\x1b[0m                        Traceback (most recent call last)', 'Cell \\x1b[0;32mIn[7], line 1\\x1b[0m\\n\\x1b[0;32m----> 1\\x1b[0m \\x1b[38;5;28;01mawait\\x1b[39;00m process_chat(chat, \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mOrchestrator: Prepare tumor board for Patient ID: patient_4\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m)\\n', 'Cell \\x1b[0;32mIn[6], line 11\\x1b[0m, in \\x1b[0;36mprocess_chat\\x1b[0;34m(chat, user_message)\\x1b[0m\\n\\x1b[1;32m      8\\x1b[0m \\x1b[38;5;28;01mawait\\x1b[39;00m chat\\x1b[38;5;241m.\\x1b[39madd_chat_message(ChatMessageContent(role\\x1b[38;5;241m=\\x1b[39mAuthorRole\\x1b[38;5;241m.\\x1b[39mUSER, content\\x1b[38;5;241m=\\x1b[39muser_message))\\n\\x1b[1;32m      9\\x1b[0m chat\\x1b[38;5;241m.\\x1b[39mis_complete \\x1b[38;5;241m=\\x1b[39m \\x1b[38;5;28;01mFalse\\x1b[39;00m\\n\\x1b[0;32m---> 11\\x1b[0m \\x1b[38;5;28;01masync\\x1b[39;00m \\x1b[38;5;28;01mfor\\x1b[39;00m response \\x1b[38;5;129;01min\\x1b[39;00m chat\\x1b[38;5;241m.\\x1b[39minvoke():\\n\\x1b[1;32m     12\\x1b[0m     \\x1b[38;5;28mprint\\x1b[39m(\\x1b[38;5;124mf\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124m# \\x1b[39m\\x1b[38;5;132;01m{\\x1b[39;00mresponse\\x1b[38;5;241m.\\x1b[39mrole\\x1b[38;5;132;01m}\\x1b[39;00m\\x1b[38;5;124m - \\x1b[39m\\x1b[38;5;132;01m{\\x1b[39;00mresponse\\x1b[38;5;241m.\\x1b[39mname\\x1b[38;5;250m \\x1b[39m\\x1b[38;5;129;01mor\\x1b[39;00m\\x1b[38;5;250m \\x1b[39m\\x1b[38;5;124m\\'\\x1b[39m\\x1b[38;5;124m*\\x1b[39m\\x1b[38;5;124m\\'\\x1b[39m\\x1b[38;5;132;01m}\\x1b[39;00m\\x1b[38;5;124m: \\x1b[39m\\x1b[38;5;124m\\'\\x1b[39m\\x1b[38;5;132;01m{\\x1b[39;00mresponse\\x1b[38;5;241m.\\x1b[39mcontent\\x1b[38;5;132;01m}\\x1b[39;00m\\x1b[38;5;124m\\'\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m)\\n\\x1b[1;32m     13\\x1b[0m     \\x1b[38;5;28;01mif\\x1b[39;00m chat\\x1b[38;5;241m.\\x1b[39mis_complete:\\n', 'File \\x1b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/agents/group_chat/agent_group_chat.py:154\\x1b[0m, in \\x1b[0;36mAgentGroupChat.invoke\\x1b[0;34m(self, agent, is_joining)\\x1b[0m\\n\\x1b[1;32m    152\\x1b[0m \\x1b[38;5;28;01mexcept\\x1b[39;00m \\x1b[38;5;167;01mException\\x1b[39;00m \\x1b[38;5;28;01mas\\x1b[39;00m ex:\\n\\x1b[1;32m    153\\x1b[0m     logger\\x1b[38;5;241m.\\x1b[39merror(\\x1b[38;5;124mf\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mFailed to select agent: \\x1b[39m\\x1b[38;5;132;01m{\\x1b[39;00mex\\x1b[38;5;132;01m}\\x1b[39;00m\\x1b[38;5;124m\"\\x1b[39m)\\n\\x1b[0;32m--> 154\\x1b[0m     \\x1b[38;5;28;01mraise\\x1b[39;00m AgentChatException(\\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mFailed to select agent\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m) \\x1b[38;5;28;01mfrom\\x1b[39;00m\\x1b[38;5;250m \\x1b[39m\\x1b[38;5;21;01mex\\x1b[39;00m\\n\\x1b[1;32m    156\\x1b[0m \\x1b[38;5;28;01masync\\x1b[39;00m \\x1b[38;5;28;01mfor\\x1b[39;00m message \\x1b[38;5;129;01min\\x1b[39;00m \\x1b[38;5;28msuper\\x1b[39m()\\x1b[38;5;241m.\\x1b[39minvoke_agent(selected_agent):\\n\\x1b[1;32m    157\\x1b[0m     \\x1b[38;5;28;01mif\\x1b[39;00m message\\x1b[38;5;241m.\\x1b[39mrole \\x1b[38;5;241m==\\x1b[39m AuthorRole\\x1b[38;5;241m.\\x1b[39mASSISTANT:\\n', '\\x1b[0;31mAgentChatException\\x1b[0m: Failed to select agent'], 'ename': 'AgentChatException', 'evalue': 'Failed to select agent', 'engine_info': {'engine_uuid': '23c0ebcd-44f5-40bd-b21c-85c722302ce7', 'engine_id': -1, 'method': 'execute'}, 'execution_count': 7, 'user_expressions': {}, 'payload': []}, 'metadata': {'started': datetime.datetime(2025, 8, 8, 20, 24, 24, 905721, tzinfo=datetime.timezone.utc), 'dependencies_met': True, 'engine': '23c0ebcd-44f5-40bd-b21c-85c722302ce7', 'status': 'error'}, 'tracker': <zmq.sugar.tracker.MessageTracker object at 0x7a2a28801d30>}\n",
      "2025-08-08 13:24:27,164 - IPKernelApp - DEBUG - {'header': {'msg_id': '571bc763-22923a1b7e800ab4f182ecfe_58456_118', 'msg_type': 'execute_reply', 'username': 'mablonde', 'session': '571bc763-22923a1b7e800ab4f182ecfe', 'date': datetime.datetime(2025, 8, 8, 20, 24, 27, 164489, tzinfo=datetime.timezone.utc), 'version': '5.3'}, 'msg_id': '571bc763-22923a1b7e800ab4f182ecfe_58456_118', 'msg_type': 'execute_reply', 'parent_header': {'date': datetime.datetime(2025, 8, 8, 20, 24, 24, 899000, tzinfo=tzutc()), 'msg_id': '8bff73fc-2beb-4dfb-92c7-172c72498c0b', 'msg_type': 'execute_request', 'session': '00adb0ca-9d5f-4df4-b793-380b7a539da0', 'username': '8dc24feb-2c65-412a-9798-1ee6e8d34202', 'version': '5.2'}, 'content': {'status': 'error', 'traceback': ['\\x1b[0;31m---------------------------------------------------------------------------\\x1b[0m', '\\x1b[0;31mBadRequestError\\x1b[0m                           Traceback (most recent call last)', 'File \\x1b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_handler.py:88\\x1b[0m, in \\x1b[0;36mOpenAIHandler._send_completion_request\\x1b[0;34m(self, settings)\\x1b[0m\\n\\x1b[1;32m     87\\x1b[0m         settings_dict\\x1b[38;5;241m.\\x1b[39mpop(\\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mparallel_tool_calls\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m, \\x1b[38;5;28;01mNone\\x1b[39;00m)\\n\\x1b[0;32m---> 88\\x1b[0m     response \\x1b[38;5;241m=\\x1b[39m \\x1b[38;5;28;01mawait\\x1b[39;00m \\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39mclient\\x1b[38;5;241m.\\x1b[39mchat\\x1b[38;5;241m.\\x1b[39mcompletions\\x1b[38;5;241m.\\x1b[39mcreate(\\x1b[38;5;241m*\\x1b[39m\\x1b[38;5;241m*\\x1b[39msettings_dict)\\n\\x1b[1;32m     89\\x1b[0m \\x1b[38;5;28;01melse\\x1b[39;00m:\\n', 'File \\x1b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:2589\\x1b[0m, in \\x1b[0;36mAsyncCompletions.create\\x1b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\\x1b[0m\\n\\x1b[1;32m   2588\\x1b[0m validate_response_format(response_format)\\n\\x1b[0;32m-> 2589\\x1b[0m \\x1b[38;5;28;01mreturn\\x1b[39;00m \\x1b[38;5;28;01mawait\\x1b[39;00m \\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39m_post(\\n\\x1b[1;32m   2590\\x1b[0m     \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124m/chat/completions\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m,\\n\\x1b[1;32m   2591\\x1b[0m     body\\x1b[38;5;241m=\\x1b[39m\\x1b[38;5;28;01mawait\\x1b[39;00m async_maybe_transform(\\n\\x1b[1;32m   2592\\x1b[0m         {\\n\\x1b[1;32m   2593\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mmessages\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: messages,\\n\\x1b[1;32m   2594\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mmodel\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: model,\\n\\x1b[1;32m   2595\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124maudio\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: audio,\\n\\x1b[1;32m   2596\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mfrequency_penalty\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: frequency_penalty,\\n\\x1b[1;32m   2597\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mfunction_call\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: function_call,\\n\\x1b[1;32m   2598\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mfunctions\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: functions,\\n\\x1b[1;32m   2599\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mlogit_bias\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: logit_bias,\\n\\x1b[1;32m   2600\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mlogprobs\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: logprobs,\\n\\x1b[1;32m   2601\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mmax_completion_tokens\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: max_completion_tokens,\\n\\x1b[1;32m   2602\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mmax_tokens\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: max_tokens,\\n\\x1b[1;32m   2603\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mmetadata\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: metadata,\\n\\x1b[1;32m   2604\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mmodalities\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: modalities,\\n\\x1b[1;32m   2605\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mn\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: n,\\n\\x1b[1;32m   2606\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mparallel_tool_calls\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: parallel_tool_calls,\\n\\x1b[1;32m   2607\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mprediction\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: prediction,\\n\\x1b[1;32m   2608\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mpresence_penalty\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: presence_penalty,\\n\\x1b[1;32m   2609\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mprompt_cache_key\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: prompt_cache_key,\\n\\x1b[1;32m   2610\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mreasoning_effort\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: reasoning_effort,\\n\\x1b[1;32m   2611\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mresponse_format\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: response_format,\\n\\x1b[1;32m   2612\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124msafety_identifier\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: safety_identifier,\\n\\x1b[1;32m   2613\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mseed\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: seed,\\n\\x1b[1;32m   2614\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mservice_tier\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: service_tier,\\n\\x1b[1;32m   2615\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mstop\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: stop,\\n\\x1b[1;32m   2616\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mstore\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: store,\\n\\x1b[1;32m   2617\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mstream\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: stream,\\n\\x1b[1;32m   2618\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mstream_options\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: stream_options,\\n\\x1b[1;32m   2619\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mtemperature\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: temperature,\\n\\x1b[1;32m   2620\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mtool_choice\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: tool_choice,\\n\\x1b[1;32m   2621\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mtools\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: tools,\\n\\x1b[1;32m   2622\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mtop_logprobs\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: top_logprobs,\\n\\x1b[1;32m   2623\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mtop_p\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: top_p,\\n\\x1b[1;32m   2624\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124muser\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: user,\\n\\x1b[1;32m   2625\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mverbosity\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: verbosity,\\n\\x1b[1;32m   2626\\x1b[0m             \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mweb_search_options\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: web_search_options,\\n\\x1b[1;32m   2627\\x1b[0m         },\\n\\x1b[1;32m   2628\\x1b[0m         completion_create_params\\x1b[38;5;241m.\\x1b[39mCompletionCreateParamsStreaming\\n\\x1b[1;32m   2629\\x1b[0m         \\x1b[38;5;28;01mif\\x1b[39;00m stream\\n\\x1b[1;32m   2630\\x1b[0m         \\x1b[38;5;28;01melse\\x1b[39;00m completion_create_params\\x1b[38;5;241m.\\x1b[39mCompletionCreateParamsNonStreaming,\\n\\x1b[1;32m   2631\\x1b[0m     ),\\n\\x1b[1;32m   2632\\x1b[0m     options\\x1b[38;5;241m=\\x1b[39mmake_request_options(\\n\\x1b[1;32m   2633\\x1b[0m         extra_headers\\x1b[38;5;241m=\\x1b[39mextra_headers, extra_query\\x1b[38;5;241m=\\x1b[39mextra_query, extra_body\\x1b[38;5;241m=\\x1b[39mextra_body, timeout\\x1b[38;5;241m=\\x1b[39mtimeout\\n\\x1b[1;32m   2634\\x1b[0m     ),\\n\\x1b[1;32m   2635\\x1b[0m     cast_to\\x1b[38;5;241m=\\x1b[39mChatCompletion,\\n\\x1b[1;32m   2636\\x1b[0m     stream\\x1b[38;5;241m=\\x1b[39mstream \\x1b[38;5;129;01mor\\x1b[39;00m \\x1b[38;5;28;01mFalse\\x1b[39;00m,\\n\\x1b[1;32m   2637\\x1b[0m     stream_cls\\x1b[38;5;241m=\\x1b[39mAsyncStream[ChatCompletionChunk],\\n\\x1b[1;32m   2638\\x1b[0m )\\n', 'File \\x1b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/openai/_base_client.py:1794\\x1b[0m, in \\x1b[0;36mAsyncAPIClient.post\\x1b[0;34m(self, path, cast_to, body, files, options, stream, stream_cls)\\x1b[0m\\n\\x1b[1;32m   1791\\x1b[0m opts \\x1b[38;5;241m=\\x1b[39m FinalRequestOptions\\x1b[38;5;241m.\\x1b[39mconstruct(\\n\\x1b[1;32m   1792\\x1b[0m     method\\x1b[38;5;241m=\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mpost\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m, url\\x1b[38;5;241m=\\x1b[39mpath, json_data\\x1b[38;5;241m=\\x1b[39mbody, files\\x1b[38;5;241m=\\x1b[39m\\x1b[38;5;28;01mawait\\x1b[39;00m async_to_httpx_files(files), \\x1b[38;5;241m*\\x1b[39m\\x1b[38;5;241m*\\x1b[39moptions\\n\\x1b[1;32m   1793\\x1b[0m )\\n\\x1b[0;32m-> 1794\\x1b[0m \\x1b[38;5;28;01mreturn\\x1b[39;00m \\x1b[38;5;28;01mawait\\x1b[39;00m \\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39mrequest(cast_to, opts, stream\\x1b[38;5;241m=\\x1b[39mstream, stream_cls\\x1b[38;5;241m=\\x1b[39mstream_cls)\\n', 'File \\x1b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/openai/_base_client.py:1594\\x1b[0m, in \\x1b[0;36mAsyncAPIClient.request\\x1b[0;34m(self, cast_to, options, stream, stream_cls)\\x1b[0m\\n\\x1b[1;32m   1593\\x1b[0m     log\\x1b[38;5;241m.\\x1b[39mdebug(\\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mRe-raising status error\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m)\\n\\x1b[0;32m-> 1594\\x1b[0m     \\x1b[38;5;28;01mraise\\x1b[39;00m \\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39m_make_status_error_from_response(err\\x1b[38;5;241m.\\x1b[39mresponse) \\x1b[38;5;28;01mfrom\\x1b[39;00m\\x1b[38;5;250m \\x1b[39m\\x1b[38;5;28;01mNone\\x1b[39;00m\\n\\x1b[1;32m   1596\\x1b[0m \\x1b[38;5;28;01mbreak\\x1b[39;00m\\n', '\\x1b[0;31mBadRequestError\\x1b[0m: Error code: 400 - {\\'error\\': {\\'message\\': \"Invalid parameter: \\'response_format\\' of type \\'json_schema\\' is not supported with this model. Learn more about supported models at the Structured Outputs guide: https://platform.openai.com/docs/guides/structured-outputs\", \\'type\\': \\'invalid_request_error\\', \\'param\\': None, \\'code\\': None}}', '\\nThe above exception was the direct cause of the following exception:\\n', '\\x1b[0;31mServiceResponseException\\x1b[0m                  Traceback (most recent call last)', 'File \\x1b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/functions/kernel_function_from_prompt.py:178\\x1b[0m, in \\x1b[0;36mKernelFunctionFromPrompt._invoke_internal\\x1b[0;34m(self, context)\\x1b[0m\\n\\x1b[1;32m    177\\x1b[0m \\x1b[38;5;28;01mtry\\x1b[39;00m:\\n\\x1b[0;32m--> 178\\x1b[0m     chat_message_contents \\x1b[38;5;241m=\\x1b[39m \\x1b[38;5;28;01mawait\\x1b[39;00m prompt_render_result\\x1b[38;5;241m.\\x1b[39mai_service\\x1b[38;5;241m.\\x1b[39mget_chat_message_contents(\\n\\x1b[1;32m    179\\x1b[0m         chat_history\\x1b[38;5;241m=\\x1b[39mchat_history,\\n\\x1b[1;32m    180\\x1b[0m         settings\\x1b[38;5;241m=\\x1b[39mprompt_render_result\\x1b[38;5;241m.\\x1b[39mexecution_settings,\\n\\x1b[1;32m    181\\x1b[0m         \\x1b[38;5;241m*\\x1b[39m\\x1b[38;5;241m*\\x1b[39m{\\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mkernel\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: context\\x1b[38;5;241m.\\x1b[39mkernel, \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124marguments\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m: context\\x1b[38;5;241m.\\x1b[39marguments},\\n\\x1b[1;32m    182\\x1b[0m     )\\n\\x1b[1;32m    183\\x1b[0m \\x1b[38;5;28;01mexcept\\x1b[39;00m \\x1b[38;5;167;01mException\\x1b[39;00m \\x1b[38;5;28;01mas\\x1b[39;00m exc:\\n', 'File \\x1b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/connectors/ai/chat_completion_client_base.py:139\\x1b[0m, in \\x1b[0;36mChatCompletionClientBase.get_chat_message_contents\\x1b[0;34m(self, chat_history, settings, **kwargs)\\x1b[0m\\n\\x1b[1;32m    138\\x1b[0m \\x1b[38;5;28;01mfor\\x1b[39;00m request_index \\x1b[38;5;129;01min\\x1b[39;00m \\x1b[38;5;28mrange\\x1b[39m(settings\\x1b[38;5;241m.\\x1b[39mfunction_choice_behavior\\x1b[38;5;241m.\\x1b[39mmaximum_auto_invoke_attempts):\\n\\x1b[0;32m--> 139\\x1b[0m     completions \\x1b[38;5;241m=\\x1b[39m \\x1b[38;5;28;01mawait\\x1b[39;00m \\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39m_inner_get_chat_message_contents(chat_history, settings)\\n\\x1b[1;32m    140\\x1b[0m     \\x1b[38;5;66;03m# Get the function call contents from the chat message. There is only one chat message,\\x1b[39;00m\\n\\x1b[1;32m    141\\x1b[0m     \\x1b[38;5;66;03m# which should be checked in the `_verify_function_choice_settings` method.\\x1b[39;00m\\n', 'File \\x1b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/utils/telemetry/model_diagnostics/decorators.py:112\\x1b[0m, in \\x1b[0;36mtrace_chat_completion.<locals>.inner_trace_chat_completion.<locals>.wrapper_decorator\\x1b[0;34m(*args, **kwargs)\\x1b[0m\\n\\x1b[1;32m    110\\x1b[0m \\x1b[38;5;28;01mif\\x1b[39;00m \\x1b[38;5;129;01mnot\\x1b[39;00m are_model_diagnostics_enabled():\\n\\x1b[1;32m    111\\x1b[0m     \\x1b[38;5;66;03m# If model diagnostics are not enabled, just return the completion\\x1b[39;00m\\n\\x1b[0;32m--> 112\\x1b[0m     \\x1b[38;5;28;01mreturn\\x1b[39;00m \\x1b[38;5;28;01mawait\\x1b[39;00m completion_func(\\x1b[38;5;241m*\\x1b[39margs, \\x1b[38;5;241m*\\x1b[39m\\x1b[38;5;241m*\\x1b[39mkwargs)\\n\\x1b[1;32m    114\\x1b[0m completion_service: \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mChatCompletionClientBase\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m \\x1b[38;5;241m=\\x1b[39m args[\\x1b[38;5;241m0\\x1b[39m]\\n', 'File \\x1b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_chat_completion_base.py:88\\x1b[0m, in \\x1b[0;36mOpenAIChatCompletionBase._inner_get_chat_message_contents\\x1b[0;34m(self, chat_history, settings)\\x1b[0m\\n\\x1b[1;32m     86\\x1b[0m settings\\x1b[38;5;241m.\\x1b[39mai_model_id \\x1b[38;5;241m=\\x1b[39m settings\\x1b[38;5;241m.\\x1b[39mai_model_id \\x1b[38;5;129;01mor\\x1b[39;00m \\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39mai_model_id\\n\\x1b[0;32m---> 88\\x1b[0m response \\x1b[38;5;241m=\\x1b[39m \\x1b[38;5;28;01mawait\\x1b[39;00m \\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39m_send_request(settings)\\n\\x1b[1;32m     89\\x1b[0m \\x1b[38;5;28;01massert\\x1b[39;00m \\x1b[38;5;28misinstance\\x1b[39m(response, ChatCompletion)  \\x1b[38;5;66;03m# nosec\\x1b[39;00m\\n', 'File \\x1b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_handler.py:60\\x1b[0m, in \\x1b[0;36mOpenAIHandler._send_request\\x1b[0;34m(self, settings)\\x1b[0m\\n\\x1b[1;32m     59\\x1b[0m     \\x1b[38;5;28;01massert\\x1b[39;00m \\x1b[38;5;28misinstance\\x1b[39m(settings, OpenAIPromptExecutionSettings)  \\x1b[38;5;66;03m# nosec\\x1b[39;00m\\n\\x1b[0;32m---> 60\\x1b[0m     \\x1b[38;5;28;01mreturn\\x1b[39;00m \\x1b[38;5;28;01mawait\\x1b[39;00m \\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39m_send_completion_request(settings)\\n\\x1b[1;32m     61\\x1b[0m \\x1b[38;5;28;01mif\\x1b[39;00m \\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39mai_model_type \\x1b[38;5;241m==\\x1b[39m OpenAIModelTypes\\x1b[38;5;241m.\\x1b[39mEMBEDDING:\\n', 'File \\x1b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_handler.py:100\\x1b[0m, in \\x1b[0;36mOpenAIHandler._send_completion_request\\x1b[0;34m(self, settings)\\x1b[0m\\n\\x1b[1;32m     96\\x1b[0m         \\x1b[38;5;28;01mraise\\x1b[39;00m ContentFilterAIException(\\n\\x1b[1;32m     97\\x1b[0m             \\x1b[38;5;124mf\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;132;01m{\\x1b[39;00m\\x1b[38;5;28mtype\\x1b[39m(\\x1b[38;5;28mself\\x1b[39m)\\x1b[38;5;132;01m}\\x1b[39;00m\\x1b[38;5;124m service encountered a content error\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m,\\n\\x1b[1;32m     98\\x1b[0m             ex,\\n\\x1b[1;32m     99\\x1b[0m         ) \\x1b[38;5;28;01mfrom\\x1b[39;00m\\x1b[38;5;250m \\x1b[39m\\x1b[38;5;21;01mex\\x1b[39;00m\\n\\x1b[0;32m--> 100\\x1b[0m     \\x1b[38;5;28;01mraise\\x1b[39;00m ServiceResponseException(\\n\\x1b[1;32m    101\\x1b[0m         \\x1b[38;5;124mf\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;132;01m{\\x1b[39;00m\\x1b[38;5;28mtype\\x1b[39m(\\x1b[38;5;28mself\\x1b[39m)\\x1b[38;5;132;01m}\\x1b[39;00m\\x1b[38;5;124m service failed to complete the prompt\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m,\\n\\x1b[1;32m    102\\x1b[0m         ex,\\n\\x1b[1;32m    103\\x1b[0m     ) \\x1b[38;5;28;01mfrom\\x1b[39;00m\\x1b[38;5;250m \\x1b[39m\\x1b[38;5;21;01mex\\x1b[39;00m\\n\\x1b[1;32m    104\\x1b[0m \\x1b[38;5;28;01mexcept\\x1b[39;00m \\x1b[38;5;167;01mException\\x1b[39;00m \\x1b[38;5;28;01mas\\x1b[39;00m ex:\\n', '\\x1b[0;31mServiceResponseException\\x1b[0m: (\"<class \\'semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion.AzureChatCompletion\\'> service failed to complete the prompt\", BadRequestError(\\'Error code: 400 - {\\\\\\'error\\\\\\': {\\\\\\'message\\\\\\': \"Invalid parameter: \\\\\\'response_format\\\\\\' of type \\\\\\'json_schema\\\\\\' is not supported with this model. Learn more about supported models at the Structured Outputs guide: https://platform.openai.com/docs/guides/structured-outputs\", \\\\\\'type\\\\\\': \\\\\\'invalid_request_error\\\\\\', \\\\\\'param\\\\\\': None, \\\\\\'code\\\\\\': None}}\\'))', '\\nThe above exception was the direct cause of the following exception:\\n', '\\x1b[0;31mFunctionExecutionException\\x1b[0m                Traceback (most recent call last)', 'File \\x1b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/agents/strategies/selection/kernel_function_selection_strategy.py:95\\x1b[0m, in \\x1b[0;36mKernelFunctionSelectionStrategy.select_agent\\x1b[0;34m(self, agents, history)\\x1b[0m\\n\\x1b[1;32m     94\\x1b[0m \\x1b[38;5;28;01mtry\\x1b[39;00m:\\n\\x1b[0;32m---> 95\\x1b[0m     result \\x1b[38;5;241m=\\x1b[39m \\x1b[38;5;28;01mawait\\x1b[39;00m \\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39mfunction\\x1b[38;5;241m.\\x1b[39minvoke(kernel\\x1b[38;5;241m=\\x1b[39m\\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39mkernel, arguments\\x1b[38;5;241m=\\x1b[39marguments)\\n\\x1b[1;32m     96\\x1b[0m \\x1b[38;5;28;01mexcept\\x1b[39;00m \\x1b[38;5;167;01mException\\x1b[39;00m \\x1b[38;5;28;01mas\\x1b[39;00m ex:\\n', 'File \\x1b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/functions/kernel_function.py:259\\x1b[0m, in \\x1b[0;36mKernelFunction.invoke\\x1b[0;34m(self, kernel, arguments, metadata, **kwargs)\\x1b[0m\\n\\x1b[1;32m    258\\x1b[0m     \\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39m_handle_exception(current_span, e, attributes)\\n\\x1b[0;32m--> 259\\x1b[0m     \\x1b[38;5;28;01mraise\\x1b[39;00m e\\n\\x1b[1;32m    260\\x1b[0m \\x1b[38;5;28;01mfinally\\x1b[39;00m:\\n', 'File \\x1b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/functions/kernel_function.py:251\\x1b[0m, in \\x1b[0;36mKernelFunction.invoke\\x1b[0;34m(self, kernel, arguments, metadata, **kwargs)\\x1b[0m\\n\\x1b[1;32m    247\\x1b[0m stack \\x1b[38;5;241m=\\x1b[39m kernel\\x1b[38;5;241m.\\x1b[39mconstruct_call_stack(\\n\\x1b[1;32m    248\\x1b[0m     filter_type\\x1b[38;5;241m=\\x1b[39mFilterTypes\\x1b[38;5;241m.\\x1b[39mFUNCTION_INVOCATION,\\n\\x1b[1;32m    249\\x1b[0m     inner_function\\x1b[38;5;241m=\\x1b[39m\\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39m_invoke_internal,\\n\\x1b[1;32m    250\\x1b[0m )\\n\\x1b[0;32m--> 251\\x1b[0m \\x1b[38;5;28;01mawait\\x1b[39;00m stack(function_context)\\n\\x1b[1;32m    253\\x1b[0m KernelFunctionLogMessages\\x1b[38;5;241m.\\x1b[39mlog_function_invoked_success(logger, \\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39mfully_qualified_name)\\n', 'File \\x1b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/functions/kernel_function_from_prompt.py:184\\x1b[0m, in \\x1b[0;36mKernelFunctionFromPrompt._invoke_internal\\x1b[0;34m(self, context)\\x1b[0m\\n\\x1b[1;32m    183\\x1b[0m \\x1b[38;5;28;01mexcept\\x1b[39;00m \\x1b[38;5;167;01mException\\x1b[39;00m \\x1b[38;5;28;01mas\\x1b[39;00m exc:\\n\\x1b[0;32m--> 184\\x1b[0m     \\x1b[38;5;28;01mraise\\x1b[39;00m FunctionExecutionException(\\x1b[38;5;124mf\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mError occurred while invoking function \\x1b[39m\\x1b[38;5;132;01m{\\x1b[39;00m\\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39mname\\x1b[38;5;132;01m}\\x1b[39;00m\\x1b[38;5;124m: \\x1b[39m\\x1b[38;5;132;01m{\\x1b[39;00mexc\\x1b[38;5;132;01m}\\x1b[39;00m\\x1b[38;5;124m\"\\x1b[39m) \\x1b[38;5;28;01mfrom\\x1b[39;00m\\x1b[38;5;250m \\x1b[39m\\x1b[38;5;21;01mexc\\x1b[39;00m\\n\\x1b[1;32m    186\\x1b[0m \\x1b[38;5;28;01mif\\x1b[39;00m \\x1b[38;5;129;01mnot\\x1b[39;00m chat_message_contents:\\n', '\\x1b[0;31mFunctionExecutionException\\x1b[0m: Error occurred while invoking function selection: (\"<class \\'semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion.AzureChatCompletion\\'> service failed to complete the prompt\", BadRequestError(\\'Error code: 400 - {\\\\\\'error\\\\\\': {\\\\\\'message\\\\\\': \"Invalid parameter: \\\\\\'response_format\\\\\\' of type \\\\\\'json_schema\\\\\\' is not supported with this model. Learn more about supported models at the Structured Outputs guide: https://platform.openai.com/docs/guides/structured-outputs\", \\\\\\'type\\\\\\': \\\\\\'invalid_request_error\\\\\\', \\\\\\'param\\\\\\': None, \\\\\\'code\\\\\\': None}}\\'))', '\\nThe above exception was the direct cause of the following exception:\\n', '\\x1b[0;31mAgentExecutionException\\x1b[0m                   Traceback (most recent call last)', 'File \\x1b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/agents/group_chat/agent_group_chat.py:151\\x1b[0m, in \\x1b[0;36mAgentGroupChat.invoke\\x1b[0;34m(self, agent, is_joining)\\x1b[0m\\n\\x1b[1;32m    150\\x1b[0m \\x1b[38;5;28;01mtry\\x1b[39;00m:\\n\\x1b[0;32m--> 151\\x1b[0m     selected_agent \\x1b[38;5;241m=\\x1b[39m \\x1b[38;5;28;01mawait\\x1b[39;00m \\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39mselection_strategy\\x1b[38;5;241m.\\x1b[39mnext(\\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39magents, \\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39mhistory\\x1b[38;5;241m.\\x1b[39mmessages)\\n\\x1b[1;32m    152\\x1b[0m \\x1b[38;5;28;01mexcept\\x1b[39;00m \\x1b[38;5;167;01mException\\x1b[39;00m \\x1b[38;5;28;01mas\\x1b[39;00m ex:\\n', 'File \\x1b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/agents/strategies/selection/selection_strategy.py:43\\x1b[0m, in \\x1b[0;36mSelectionStrategy.next\\x1b[0;34m(self, agents, history)\\x1b[0m\\n\\x1b[1;32m     42\\x1b[0m \\x1b[38;5;28;01melse\\x1b[39;00m:\\n\\x1b[0;32m---> 43\\x1b[0m     agent \\x1b[38;5;241m=\\x1b[39m \\x1b[38;5;28;01mawait\\x1b[39;00m \\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39mselect_agent(agents, history)\\n\\x1b[1;32m     45\\x1b[0m \\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39mhas_selected \\x1b[38;5;241m=\\x1b[39m \\x1b[38;5;28;01mTrue\\x1b[39;00m\\n', 'File \\x1b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/agents/strategies/selection/kernel_function_selection_strategy.py:98\\x1b[0m, in \\x1b[0;36mKernelFunctionSelectionStrategy.select_agent\\x1b[0;34m(self, agents, history)\\x1b[0m\\n\\x1b[1;32m     97\\x1b[0m     logger\\x1b[38;5;241m.\\x1b[39merror(\\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mKernel Function Selection Strategy next method failed\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m, exc_info\\x1b[38;5;241m=\\x1b[39mex)\\n\\x1b[0;32m---> 98\\x1b[0m     \\x1b[38;5;28;01mraise\\x1b[39;00m AgentExecutionException(\\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mAgent Failure - Strategy failed to execute function.\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m) \\x1b[38;5;28;01mfrom\\x1b[39;00m\\x1b[38;5;250m \\x1b[39m\\x1b[38;5;21;01mex\\x1b[39;00m\\n\\x1b[1;32m    100\\x1b[0m logger\\x1b[38;5;241m.\\x1b[39minfo(\\n\\x1b[1;32m    101\\x1b[0m     \\x1b[38;5;124mf\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mKernel Function Selection Strategy next method completed: \\x1b[39m\\x1b[38;5;124m\"\\x1b[39m\\n\\x1b[1;32m    102\\x1b[0m     \\x1b[38;5;124mf\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;132;01m{\\x1b[39;00m\\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39mfunction\\x1b[38;5;241m.\\x1b[39mplugin_name\\x1b[38;5;132;01m}\\x1b[39;00m\\x1b[38;5;124m, \\x1b[39m\\x1b[38;5;132;01m{\\x1b[39;00m\\x1b[38;5;28mself\\x1b[39m\\x1b[38;5;241m.\\x1b[39mfunction\\x1b[38;5;241m.\\x1b[39mname\\x1b[38;5;132;01m}\\x1b[39;00m\\x1b[38;5;124m, result: \\x1b[39m\\x1b[38;5;132;01m{\\x1b[39;00mresult\\x1b[38;5;241m.\\x1b[39mvalue\\x1b[38;5;250m \\x1b[39m\\x1b[38;5;28;01mif\\x1b[39;00m\\x1b[38;5;250m \\x1b[39mresult\\x1b[38;5;250m \\x1b[39m\\x1b[38;5;28;01melse\\x1b[39;00m\\x1b[38;5;250m \\x1b[39m\\x1b[38;5;28;01mNone\\x1b[39;00m\\x1b[38;5;132;01m}\\x1b[39;00m\\x1b[38;5;124m\"\\x1b[39m,\\n\\x1b[1;32m    103\\x1b[0m )\\n', '\\x1b[0;31mAgentExecutionException\\x1b[0m: Agent Failure - Strategy failed to execute function.', '\\nThe above exception was the direct cause of the following exception:\\n', '\\x1b[0;31mAgentChatException\\x1b[0m                        Traceback (most recent call last)', 'Cell \\x1b[0;32mIn[7], line 1\\x1b[0m\\n\\x1b[0;32m----> 1\\x1b[0m \\x1b[38;5;28;01mawait\\x1b[39;00m process_chat(chat, \\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mOrchestrator: Prepare tumor board for Patient ID: patient_4\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m)\\n', 'Cell \\x1b[0;32mIn[6], line 11\\x1b[0m, in \\x1b[0;36mprocess_chat\\x1b[0;34m(chat, user_message)\\x1b[0m\\n\\x1b[1;32m      8\\x1b[0m \\x1b[38;5;28;01mawait\\x1b[39;00m chat\\x1b[38;5;241m.\\x1b[39madd_chat_message(ChatMessageContent(role\\x1b[38;5;241m=\\x1b[39mAuthorRole\\x1b[38;5;241m.\\x1b[39mUSER, content\\x1b[38;5;241m=\\x1b[39muser_message))\\n\\x1b[1;32m      9\\x1b[0m chat\\x1b[38;5;241m.\\x1b[39mis_complete \\x1b[38;5;241m=\\x1b[39m \\x1b[38;5;28;01mFalse\\x1b[39;00m\\n\\x1b[0;32m---> 11\\x1b[0m \\x1b[38;5;28;01masync\\x1b[39;00m \\x1b[38;5;28;01mfor\\x1b[39;00m response \\x1b[38;5;129;01min\\x1b[39;00m chat\\x1b[38;5;241m.\\x1b[39minvoke():\\n\\x1b[1;32m     12\\x1b[0m     \\x1b[38;5;28mprint\\x1b[39m(\\x1b[38;5;124mf\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124m# \\x1b[39m\\x1b[38;5;132;01m{\\x1b[39;00mresponse\\x1b[38;5;241m.\\x1b[39mrole\\x1b[38;5;132;01m}\\x1b[39;00m\\x1b[38;5;124m - \\x1b[39m\\x1b[38;5;132;01m{\\x1b[39;00mresponse\\x1b[38;5;241m.\\x1b[39mname\\x1b[38;5;250m \\x1b[39m\\x1b[38;5;129;01mor\\x1b[39;00m\\x1b[38;5;250m \\x1b[39m\\x1b[38;5;124m\\'\\x1b[39m\\x1b[38;5;124m*\\x1b[39m\\x1b[38;5;124m\\'\\x1b[39m\\x1b[38;5;132;01m}\\x1b[39;00m\\x1b[38;5;124m: \\x1b[39m\\x1b[38;5;124m\\'\\x1b[39m\\x1b[38;5;132;01m{\\x1b[39;00mresponse\\x1b[38;5;241m.\\x1b[39mcontent\\x1b[38;5;132;01m}\\x1b[39;00m\\x1b[38;5;124m\\'\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m)\\n\\x1b[1;32m     13\\x1b[0m     \\x1b[38;5;28;01mif\\x1b[39;00m chat\\x1b[38;5;241m.\\x1b[39mis_complete:\\n', 'File \\x1b[0;32m~/miniforge3/envs/biomed/lib/python3.12/site-packages/semantic_kernel/agents/group_chat/agent_group_chat.py:154\\x1b[0m, in \\x1b[0;36mAgentGroupChat.invoke\\x1b[0;34m(self, agent, is_joining)\\x1b[0m\\n\\x1b[1;32m    152\\x1b[0m \\x1b[38;5;28;01mexcept\\x1b[39;00m \\x1b[38;5;167;01mException\\x1b[39;00m \\x1b[38;5;28;01mas\\x1b[39;00m ex:\\n\\x1b[1;32m    153\\x1b[0m     logger\\x1b[38;5;241m.\\x1b[39merror(\\x1b[38;5;124mf\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mFailed to select agent: \\x1b[39m\\x1b[38;5;132;01m{\\x1b[39;00mex\\x1b[38;5;132;01m}\\x1b[39;00m\\x1b[38;5;124m\"\\x1b[39m)\\n\\x1b[0;32m--> 154\\x1b[0m     \\x1b[38;5;28;01mraise\\x1b[39;00m AgentChatException(\\x1b[38;5;124m\"\\x1b[39m\\x1b[38;5;124mFailed to select agent\\x1b[39m\\x1b[38;5;124m\"\\x1b[39m) \\x1b[38;5;28;01mfrom\\x1b[39;00m\\x1b[38;5;250m \\x1b[39m\\x1b[38;5;21;01mex\\x1b[39;00m\\n\\x1b[1;32m    156\\x1b[0m \\x1b[38;5;28;01masync\\x1b[39;00m \\x1b[38;5;28;01mfor\\x1b[39;00m message \\x1b[38;5;129;01min\\x1b[39;00m \\x1b[38;5;28msuper\\x1b[39m()\\x1b[38;5;241m.\\x1b[39minvoke_agent(selected_agent):\\n\\x1b[1;32m    157\\x1b[0m     \\x1b[38;5;28;01mif\\x1b[39;00m message\\x1b[38;5;241m.\\x1b[39mrole \\x1b[38;5;241m==\\x1b[39m AuthorRole\\x1b[38;5;241m.\\x1b[39mASSISTANT:\\n', '\\x1b[0;31mAgentChatException\\x1b[0m: Failed to select agent'], 'ename': 'AgentChatException', 'evalue': 'Failed to select agent', 'engine_info': {'engine_uuid': '23c0ebcd-44f5-40bd-b21c-85c722302ce7', 'engine_id': -1, 'method': 'execute'}, 'execution_count': 7, 'user_expressions': {}, 'payload': []}, 'metadata': {'started': datetime.datetime(2025, 8, 8, 20, 24, 24, 905721, tzinfo=datetime.timezone.utc), 'dependencies_met': True, 'engine': '23c0ebcd-44f5-40bd-b21c-85c722302ce7', 'status': 'error'}, 'tracker': <zmq.sugar.tracker.MessageTracker object at 0x7a2a28801d30>}\n"
     ]
    }
   ],
   "source": [
    "await process_chat(chat, \"Orchestrator: Prepare tumor board for Patient ID: patient_4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await process_chat(chat, \"Orchestrator: proceed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following line to print the chat history\n",
    "# print_chat_history(chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following line to proceed with the chat\n",
    "# await process_chat(chat, \"Orchestrator: this information will be obtained by PatientHistory\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biomed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
